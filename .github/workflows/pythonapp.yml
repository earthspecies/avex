# Boiler plate test suit for ESP projects
# NOTE: Caching should be benchmarked, unsure about the benefits
# TODO (OSS): change my_dummy_library with the folder of your
# own library to test.

name: ESP Project CI

# Runs on pushes to master and all pull requests
on:    # yamllint disable-line rule:truthy
    push:
        branches: [main]
    pull_request:

jobs:
    tests:
        name: Tests
        runs-on: ubuntu-latest
        permissions:
            contents: read
            id-token: write
        env:
            HF_TOKEN: ${{ secrets.HF_TOKEN }}

        # Run CI on a single Python version to keep checks simple
        strategy:
            matrix:
                python-version: ["3.10"]
        steps:
            - uses: actions/checkout@v2

            - name: Free disk space on runner
              run: |
                echo "Before cleanup:"
                df -h /

                sudo rm -rf /usr/share/dotnet || true
                sudo rm -rf /opt/ghc || true
                sudo rm -rf /usr/local/lib/android || true
                sudo rm -rf /usr/share/swift || true

                sudo apt-get clean || true

                echo "After cleanup:"
                df -h /

            - name: Install uv
              uses: astral-sh/setup-uv@v5
              with:
                  enable-cache: true

            - name: Set up Python ${{ matrix.python-version }}
              uses: actions/setup-python@v5
              with:
                  python-version: ${{ matrix.python-version }}

            - name: Install dependencies
              run: uv sync

            - name: Display Python version
              run: python -c "import sys; print(sys.version)"

            - name: Consistency tests with pytest
              run: |
                  uv run pytest tests/consistency --base_folder avex
            - name: Unittests with pytest
              run: |
                  uv run pytest tests/unittests
            # TODO: Remove --ignore flags once esp_data is public
            - name: Doctests with pytest
              run: |
                  uv run pytest --doctest-modules avex \
                    --ignore=avex/run_train.py \
                    --ignore=avex/run_evaluate.py \
                    --ignore=avex/data \
                    --ignore=avex/training \
                    --ignore=avex/evaluation \
                    --ignore=avex/utils/experiment_tracking.py \
                    --ignore=avex/models/atst_frame
            - name: Integration tests with pytest
              run: |
                  uv run pytest tests/integration -m "not slow" -vv --durations=20
