{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gnpag3641HUA"
   },
   "source": [
    "# SL-BEATs Model Demo\n",
    "\n",
    "This notebook demonstrates how to use the `representation-learning` package with the `sl-beats` model for:\n",
    "1. Classification using the original head\n",
    "2. Adding a new classification head\n",
    "3. Embedding extraction\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to authenticate and install the package from the private PyPI repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V42OzQzE1HUD"
   },
   "source": [
    "## Step 1: Authenticate with Google Cloud\n",
    "\n",
    "**For Google Colab**: You need to authenticate to access the private PyPI package.\n",
    "\n",
    "**For Local Execution**: If you're running this locally and already have `gcloud` configured, you can skip this step or run the authentication commands in your terminal first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uyk8A7aQ1HUD",
    "outputId": "598dd8da-4b50-4807-bce2-d685a7a00a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to the following link in your browser, and complete the sign-in prompts:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=mtjtsgfisshNl9eyasBT2JTMFubLGk&prompt=consent&token_usage=remote&access_type=offline&code_challenge=1M87PhDVsH6O77-4xIBT3GtXbZmZ_2p-7gJsTEQQvlc&code_challenge_method=S256\n",
      "\n",
      "Once finished, enter the verification code provided in your browser: 4/0Ab32j93qeGjXgvqNOycIJJgRTlJng0ky_xnVToPf5mhiGwk2neGuxBobKYKBJQ0zYUX1Yw\n",
      "\n",
      "You are now logged in as [marius@earthspecies.org].\n",
      "Your current project is [None].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n",
      "Go to the following link in your browser, and complete the sign-in prompts:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=NhE9icxKqqpxmDyfhn9hjkinWvU5ij&prompt=consent&token_usage=remote&access_type=offline&code_challenge=MoYMF3UOJSLcXKV_jFRfpPTk7aspew1nCtigqmn94fs&code_challenge_method=S256\n",
      "\n",
      "Once finished, enter the verification code provided in your browser: 4/0Ab32j901W01zKn6aCQBBbMy2hyDn_0wXbTYN3NIascC90idL3ODSGIyn16QyKOOMZM69JQ\n",
      "\n",
      "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\u001b[1;33mWARNING:\u001b[0m \n",
      "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
     ]
    }
   ],
   "source": [
    "# Authenticate with Google Cloud\n",
    "import importlib.util\n",
    "import subprocess\n",
    "\n",
    "# Check if we're in Colab\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Colab-specific authentication\n",
    "    get_ipython().system(\"gcloud auth login --no-launch-browser\")\n",
    "    get_ipython().system(\"gcloud auth application-default login --no-launch-browser\")\n",
    "else:\n",
    "    # Local execution - check if already authenticated\n",
    "    print(\"Running locally. Checking gcloud authentication...\")\n",
    "    try:\n",
    "        result = subprocess.run([\"gcloud\", \"auth\", \"list\"], capture_output=True, text=True, check=False)\n",
    "        if \"ACTIVE\" in result.stdout:\n",
    "            print(\"‚úÖ Already authenticated with gcloud\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Not authenticated. Please run in terminal:\")\n",
    "            print(\"   gcloud auth login\")\n",
    "            print(\"   gcloud auth application-default login\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è  gcloud CLI not found. Please install it or authenticate manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdTWTd1F1HUE"
   },
   "source": [
    "## Step 2: Install UV and Keyring Plugin\n",
    "\n",
    "Install `uv` package manager and the Google Artifact Registry authentication plugin.\n",
    "\n",
    "**For Local Execution**: If you already have `uv` installed and the package is available locally, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t--1-m4t1HUE",
    "outputId": "af31d07b-57f1-4982-afb4-753b92c7f003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ uv is already installed\n",
      "`\u001b[36mkeyring\u001b[39m` is already installed\n"
     ]
    }
   ],
   "source": [
    "# Install uv\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "uv_installed = shutil.which(\"uv\") is not None\n",
    "\n",
    "if not uv_installed:\n",
    "    print(\"Installing uv...\")\n",
    "    try:\n",
    "        get_ipython().system(\"pip install uv\")\n",
    "    except NameError:\n",
    "        subprocess.run([\"pip\", \"install\", \"uv\"], check=False)\n",
    "else:\n",
    "    print(\"‚úÖ uv is already installed\")\n",
    "\n",
    "# Install keyring\n",
    "try:\n",
    "    get_ipython().system(\"uv tool install keyring --with keyrings.google-artifactregistry-auth\")\n",
    "except NameError:\n",
    "    subprocess.run([\"uv\", \"tool\", \"install\", \"keyring\", \"--with\", \"keyrings.google-artifactregistry-auth\"], check=False)\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è  Keyring installation may have failed. If running locally with the package already installed, this is OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWF2HTCC1HUE"
   },
   "source": [
    "## Step 3: Configure UV for Private PyPI\n",
    "\n",
    "Create a `pyproject.toml` configuration file to use the private index.\n",
    "\n",
    "**For Local Execution**: If you're running from the project root, this will append to existing pyproject.toml or create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9ZkZuWz1HUF",
    "outputId": "8d68ab25-1106-4e64-e1d7-8a184b1c5ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created pyproject.toml configuration\n",
      "   Note: Using [[tool.uv.index]] (double brackets) as required by uv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Check if we're in the project root (has existing pyproject.toml with project config)\n",
    "current_dir = Path.cwd()\n",
    "existing_pyproject = current_dir / \"pyproject.toml\"\n",
    "\n",
    "# Check if existing pyproject.toml has [project] section (indicates it's a real project)\n",
    "has_project_config = False\n",
    "needs_fix = False\n",
    "if existing_pyproject.exists():\n",
    "    try:\n",
    "        content = existing_pyproject.read_text()\n",
    "        if \"[project]\" in content or \"[build-system]\" in content:\n",
    "            has_project_config = True\n",
    "            print(\"‚ö†Ô∏è  Found existing pyproject.toml with project configuration\")\n",
    "            print(\"   We'll append our index configuration to it...\")\n",
    "        # Check if it has wrong format (single brackets instead of double)\n",
    "        if \"[tool.uv.index]\" in content and \"[[tool.uv.index]]\" not in content:\n",
    "            needs_fix = True\n",
    "            print(\"‚ö†Ô∏è  Found incorrect format in pyproject.toml (single brackets)\")\n",
    "            print(\"   Fixing format by replacing [tool.uv.index] with [[tool.uv.index]]...\")\n",
    "            # Fix the format\n",
    "            content = content.replace(\"[tool.uv.index]\", \"[[tool.uv.index]]\")\n",
    "            with open(\"pyproject.toml\", \"w\") as f:\n",
    "                f.write(content)\n",
    "            print(\"   ‚úÖ Fixed format in existing pyproject.toml\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not read existing pyproject.toml: {e}\")\n",
    "\n",
    "# Create/update pyproject.toml configuration\n",
    "# NOTE: Use [[tool.uv.index]] (double brackets) for array of tables - this is REQUIRED by uv\n",
    "pyproject_content = \"\"\"[[tool.uv.index]]\n",
    "name = \"esp-pypi\"\n",
    "url = \"https://oauth2accesstoken@us-central1-python.pkg.dev/okapi-274503/esp-pypi/simple/\"\n",
    "explicit = true\n",
    "\n",
    "[tool.uv.sources]\n",
    "representation-learning = { index = \"esp-pypi\" }\n",
    "\n",
    "[tool.uv]\n",
    "keyring-provider = \"subprocess\"\n",
    "\"\"\"\n",
    "\n",
    "if has_project_config and not needs_fix:\n",
    "    # Append to existing file (only if we didn't just fix it)\n",
    "    with open(\"pyproject.toml\", \"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(pyproject_content)\n",
    "    print(\"‚úÖ Appended index configuration to existing pyproject.toml\")\n",
    "else:\n",
    "    # Create new file or overwrite if we fixed the format\n",
    "    if not has_project_config:\n",
    "        with open(\"pyproject.toml\", \"w\") as f:\n",
    "            f.write(pyproject_content)\n",
    "        print(\"‚úÖ Created pyproject.toml configuration\")\n",
    "    print(\"   Note: Using [[tool.uv.index]] (double brackets) as required by uv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HwVUTBb1HUF"
   },
   "source": [
    "## Step 4: Install representation-learning Package\n",
    "\n",
    "Install the package using `uv` with the configured private index.\n",
    "\n",
    "**Note**: We'll try `uv add` first (which reads pyproject.toml), then fall back to direct index URL if needed.\n",
    "\n",
    "**For Local Execution**: If the package is already installed in your environment (e.g., via `uv sync`), you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDILHKtL-C-R",
    "outputId": "9438bea5-945b-4b5b-e6d6-5fd84a4ce1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 130ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install numpy first to avoid compatibility issues\n",
    "!pip install numpy==1.26.4\n",
    "!uv pip install representation-learning --extra-index-url https://oauth2accesstoken@us-central1-python.pkg.dev/okapi-274503/esp-pypi/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO8PKJCq1HUG"
   },
   "source": [
    "## Step 5: Import and Verify Installation\n",
    "\n",
    "Import the package and verify it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmaDfmym1HUG",
    "outputId": "acc8723b-c55f-4fea-aa1a-a879aa95c12f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:representation_learning.models.utils.registry:Failed to load models from package representation_learning.configs.official_models: No module named 'representation_learning.configs.official_models'; 'representation_learning.configs' is not a package\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Package imported successfully!\n",
      "PyTorch version: 2.5.0+cu124\n",
      "CUDA available: False\n",
      "\n",
      "üìã Available models:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from representation_learning import list_models, load_model\n",
    "\n",
    "print(\"‚úÖ Package imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# List available models\n",
    "print(\"\\nüìã Available models:\")\n",
    "models = list_models()\n",
    "for name in list(models.keys())[:5]:  # Show first 5\n",
    "    print(f\"  - {name}\")\n",
    "if len(models) > 5:\n",
    "    print(f\"  ... and {len(models) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNpWTwWG1HUG"
   },
   "source": [
    "## Step 6: Use Case 1 - Classification with Original Head\n",
    "\n",
    "Load the `sl_beats_animalspeak` model with its original classification head from the checkpoint.\n",
    "When `num_classes=None`, the model will extract the number of classes from the checkpoint and load the trained classifier weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2flrcwu1HUG"
   },
   "outputs": [],
   "source": [
    "print(\"üöÄ Use Case 1: Classification with Original Head\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Determine device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "try:\n",
    "    # Load model with original classifier (num_classes=None extracts from checkpoint)\n",
    "    model = load_model(\"sl_beats_animalspeak\", num_classes=None, device=device)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "    print(f\"   Model type: {type(model).__name__}\")\n",
    "\n",
    "    # Check if classifier exists\n",
    "    if hasattr(model, \"classifier\") and model.classifier is not None:\n",
    "        print(\"   ‚úÖ Original classifier loaded from checkpoint\")\n",
    "        print(f\"   Classifier weight shape: {model.classifier.weight.shape}\")\n",
    "        print(f\"   Classifier bias shape: {model.classifier.bias.shape}\")\n",
    "        num_classes = model.classifier.weight.shape[0]\n",
    "        print(f\"   Number of classes: {num_classes}\")\n",
    "\n",
    "        # Check for class mapping\n",
    "        if hasattr(model, \"class_mapping\") and model.class_mapping:\n",
    "            index_to_label = model.class_mapping.get(\"index_to_label\", {})\n",
    "            print(f\"   Class mapping available: {len(index_to_label)} classes\")\n",
    "            if index_to_label:\n",
    "                print(\"   Sample classes:\")\n",
    "                for idx in list(index_to_label.keys())[:5]:\n",
    "                    print(f\"     {idx}: {index_to_label[idx]}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No classifier found (model in embedding mode)\")\n",
    "\n",
    "    # Test forward pass\n",
    "    print(\"\\nüß™ Testing forward pass...\")\n",
    "    dummy_input = torch.randn(1, 16000 * 5)  # 5 seconds of audio at 16kHz\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input, padding_mask=None)\n",
    "\n",
    "    print(f\"   Input shape: {dummy_input.shape}\")\n",
    "    print(f\"   Output shape: {output.shape}\")\n",
    "\n",
    "    if hasattr(model, \"classifier\") and model.classifier is not None:\n",
    "        # Get predictions\n",
    "        probs = torch.softmax(output, dim=-1)\n",
    "        top_probs, top_indices = torch.topk(probs, k=min(3, output.shape[-1]), dim=-1)\n",
    "        print(\"\\n   Top-3 predictions:\")\n",
    "        for i, (prob, idx) in enumerate(zip(top_probs[0], top_indices[0], strict=False)):\n",
    "            idx_int = idx.item()\n",
    "            if hasattr(model, \"class_mapping\") and model.class_mapping:\n",
    "                index_to_label = model.class_mapping.get(\"index_to_label\", {})\n",
    "                label = index_to_label.get(idx_int, f\"Class {idx_int}\")\n",
    "                print(f\"     {i + 1}. {label}: {prob.item():.4f}\")\n",
    "            else:\n",
    "                print(f\"     {i + 1}. Class {idx_int}: {prob.item():.4f}\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Model returns embeddings (not classification logits)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXpLVchd1HUG"
   },
   "source": [
    "## Step 7: Use Case 2 - Adding a New Classification Head\n",
    "\n",
    "Load the model and add a new classification head with a different number of classes.\n",
    "When `num_classes` is explicitly provided, the classifier weights are randomly initialized (not loaded from checkpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ksAZbLO1HUG"
   },
   "outputs": [],
   "source": [
    "print(\"üöÄ Use Case 2: Adding a New Classification Head\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Load model with a new classifier (explicit num_classes)\n",
    "    new_num_classes = 20\n",
    "    print(f\"Creating new classifier with {new_num_classes} classes...\")\n",
    "\n",
    "    model = load_model(\"sl_beats_animalspeak\", num_classes=new_num_classes, device=device)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"\\n‚úÖ Model loaded with new classifier!\")\n",
    "\n",
    "    if hasattr(model, \"classifier\") and model.classifier is not None:\n",
    "        print(\"   ‚úÖ New classifier created\")\n",
    "        print(f\"   Classifier weight shape: {model.classifier.weight.shape}\")\n",
    "        print(f\"   Classifier bias shape: {model.classifier.bias.shape}\")\n",
    "        print(f\"   Number of classes: {new_num_classes}\")\n",
    "        print(\"   üí° Note: Classifier weights are randomly initialized (not from checkpoint)\")\n",
    "    else:\n",
    "        print(\"   ‚ùå No classifier found\")\n",
    "\n",
    "    # Test forward pass\n",
    "    print(\"\\nüß™ Testing forward pass...\")\n",
    "    dummy_input = torch.randn(1, 16000 * 5)  # 5 seconds of audio\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input, padding_mask=None)\n",
    "\n",
    "    print(f\"   Input shape: {dummy_input.shape}\")\n",
    "    print(f\"   Output shape: {output.shape}\")\n",
    "    print(f\"   ‚úÖ Model outputs classification logits for {new_num_classes} classes\")\n",
    "\n",
    "    print(\"\\nüí° This classifier can be trained for your specific task!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze9-xTCP1HUG"
   },
   "source": [
    "## Step 8: Use Case 3 - Embedding Extraction\n",
    "\n",
    "Load the model in embedding extraction mode. This is useful for:\n",
    "- Transfer learning\n",
    "- Linear probing\n",
    "- Feature extraction for downstream tasks\n",
    "\n",
    "When loading with `return_features_only=True`, the model returns embeddings instead of classification logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-bPZjLM1HUH"
   },
   "outputs": [],
   "source": [
    "print(\"üöÄ Use Case 3: Embedding Extraction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Load model for embedding extraction using return_features_only=True\n",
    "    print(\"Loading sl_beats_animalspeak in embedding extraction mode...\")\n",
    "    print(\"(Using return_features_only=True to extract embeddings)\")\n",
    "\n",
    "    model = load_model(\"sl_beats_animalspeak\", num_classes=None, return_features_only=True, device=device)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"\\n‚úÖ Model loaded in embedding extraction mode!\")\n",
    "\n",
    "    # Check if classifier exists\n",
    "    has_classifier = hasattr(model, \"classifier\") and model.classifier is not None\n",
    "    if has_classifier:\n",
    "        print(\"   ‚ö†Ô∏è  Model has a classifier (unexpected for embedding mode)\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Model has no classifier (embedding extraction mode)\")\n",
    "        print(f\"   Return features only: {getattr(model, '_return_features_only', 'N/A')}\")\n",
    "\n",
    "    # Test forward pass - should return embeddings\n",
    "    print(\"\\nüß™ Testing forward pass...\")\n",
    "    dummy_input = torch.randn(1, 16000 * 5)  # 5 seconds of audio\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input, padding_mask=None)\n",
    "\n",
    "    print(f\"   Input shape: {dummy_input.shape}\")\n",
    "    print(f\"   Output shape: {output.shape}\")\n",
    "    print(f\"   ‚úÖ Model returns embeddings (dimension: {output.shape[-1]})\")\n",
    "\n",
    "    # Show embedding statistics\n",
    "    print(\"\\nüìä Embedding statistics:\")\n",
    "    print(f\"   Mean: {output.mean().item():.4f}\")\n",
    "    print(f\"   Std: {output.std().item():.4f}\")\n",
    "    print(f\"   Min: {output.min().item():.4f}\")\n",
    "    print(f\"   Max: {output.max().item():.4f}\")\n",
    "\n",
    "    print(\"\\nüí° These embeddings can be used for:\")\n",
    "    print(\"   - Linear probing (training a simple classifier on top)\")\n",
    "    print(\"   - Similarity search\")\n",
    "    print(\"   - Clustering\")\n",
    "    print(\"   - Transfer learning to new tasks\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBWK8Hij1HUH"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated three main use cases for the `sl-beats` model:\n",
    "\n",
    "1. **Classification with Original Head**: Load the model with `num_classes=None` to use the trained classifier from the checkpoint.\n",
    "\n",
    "2. **Adding a New Classification Head**: Load the model with an explicit `num_classes` to create a new randomly initialized classifier for your specific task.\n",
    "\n",
    "3. **Embedding Extraction**: Load the model with `return_features_only=True` to extract features for downstream tasks.\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- `num_classes=None`: Extracts number of classes from checkpoint and loads trained classifier\n",
    "- `num_classes=<number>`: Creates a new randomly initialized classifier\n",
    "- `return_features_only=True`: Loads model in embedding extraction mode (no classifier)\n",
    "- The model backbone can be accessed directly for custom feature extraction\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Train the new classifier on your dataset\n",
    "- Use embeddings for linear probing or similarity search\n",
    "- Fine-tune the entire model for your specific task"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}