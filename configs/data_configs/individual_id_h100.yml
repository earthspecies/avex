benchmark_name: "individual_id_benchmark"

evaluation_sets:
  - name: "pipit_id_across_year"
    train: &pipit_base
      dataset_name: "pipit_id"
      split: "train_across_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    validation:
      <<: *pipit_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    test:
      dataset_name: "pipit_id"
      split: "test_across_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  - name: "pipit_id_across_year_train_vs_test"
    train: &pipit_retrieval_base
      dataset_name: "pipit_id"
      split: "train_across_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    validation:
      <<: *pipit_retrieval_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    test:
      dataset_name: "pipit_id"
      split: "test_across_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]
    retrieval_mode: "train_vs_test"

  - name: "chiffchaff_id_across_year"
    train: &chiffchaff_base
      dataset_name: "chiffchaff_id"
      split: "train_across_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    validation:
      <<: *chiffchaff_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    test:
      dataset_name: "chiffchaff_id"
      split: "test_across_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  - name: "chiffchaff_id_across_year_train_vs_test"
    train: &chiffchaff_retrieval_base
      dataset_name: "chiffchaff_id"
      split: "train_across_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    validation:
      <<: *chiffchaff_retrieval_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    test:
      dataset_name: "chiffchaff_id"
      split: "test_across_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    metrics: ["accuracy", "clustering_ari", "clustering_nmi"]
    retrieval_mode: "train_vs_test"

  # =====================================================
  # WITHIN-YEAR INDIVIDUAL ID TASKS
  # =====================================================

  - name: "pipit_id_within_year"
    train: &pipit_within_base
      dataset_name: "pipit_id"
      split: "train_within_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    validation:
      <<: *pipit_within_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    test:
      dataset_name: "pipit_id"
      split: "test_within_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {212: 0, 312: 1, 712: 2, 811: 3, 911: 4, 1011: 5, 1211: 6, 1511: 7, 1611: 8, 1711: 9}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  - name: "chiffchaff_id_within_year"
    train: &chiffchaff_within_base
      dataset_name: "chiffchaff_id"
      split: "train_within_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    validation:
      <<: *chiffchaff_within_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    test:
      dataset_name: "chiffchaff_id"
      split: "test_within_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'F72726': 0, 'F91903': 1, 'F91907': 2, 'F91913': 3, 'F91915': 4, 'F91916': 5, 'F91954': 6, 'F91959': 7, 'F91969': 8, 'F91973': 9}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  - name: "littleowl_id_within_year"
    train: &littleowl_within_base
      dataset_name: "littleowl_id"
      split: "train_within_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    validation:
      <<: *littleowl_within_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    test:
      dataset_name: "littleowl_id"
      split: "test_within_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  # =====================================================
  # MACAQUE INDIVIDUAL IDENTIFICATION TASKS
  # =====================================================

  - name: "macaques_individual_id"
    train:
      dataset_name: "macaques_coo_calls"
      split: "train"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "id"
          override: true
          label_map: {'AL': 0, 'BE': 1, 'IO': 2, 'MU': 3, 'QU': 4, 'SN': 5, 'TH': 6, 'TW': 7}

    validation:
      dataset_name: "macaques_coo_calls"
      split: "val"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "id"
          override: true
          label_map: {'AL': 0, 'BE': 1, 'IO': 2, 'MU': 3, 'QU': 4, 'SN': 5, 'TH': 6, 'TW': 7}

    test:
      dataset_name: "macaques_coo_calls"
      split: "test"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "id"
          override: true
          label_map: {'AL': 0, 'BE': 1, 'IO': 2, 'MU': 3, 'QU': 4, 'SN': 5, 'TH': 6, 'TW': 7}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  - name: "littleowl_id_across_year"
    train: &littleowl_base
      dataset_name: "littleowl_id"
      split: "train_across_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    validation:
      <<: *littleowl_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    test:
      dataset_name: "littleowl_id"
      split: "test_across_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  - name: "littleowl_id_across_year_train_vs_test"
    train: &littleowl_retrieval_base
      dataset_name: "littleowl_id"
      split: "train_across_year"
      sample_rate: 16000
      transformations:
        # First split the data into train/validation subsets
        - type: "train_val_split"
          subset: "train"
          train_size: 0.8
          random_state: 42
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    validation:
      <<: *littleowl_retrieval_base
      transformations:
        # First split the data into train/validation subsets (get validation portion)
        - type: "train_val_split"
          subset: "validation"
          train_size: 0.8
          random_state: 42  # Same random state to ensure complementary splits
          stratify_column: "individual_id"
        # Then create the label mapping from the resulting subset
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    test:
      dataset_name: "littleowl_id"
      split: "test_across_year"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "individual_id"
          override: true
          label_map: {'108': 0, '193': 1, '229': 2, '7': 3, '94': 4, 'BRE': 5, 'CER': 6, 'DUB': 7, 'KME': 8, 'LIS': 9, 'MNE': 10, 'PAL': 11, 'RAC': 12, 'RADBF': 13, 'RADK': 14, 'VEV': 15}

    metrics: ["accuracy", "clustering_ari", "clustering_nmi"]
    retrieval_mode: "train_vs_test"


  # # =====================================================
  # # VOCAL REPERTOIRE CLASSIFICATION TASKS
  # # =====================================================

  - name: "zebra_finch_call_type"
    train: &zebra_finch_train
      dataset_name: "zebra_finch_julie_elie"
      split: "train"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "call_type_1"
          override: true
          label_map: {'alarm': 0, 'contact': 1, 'distress': 2, 'nest': 3, 'unknown': 4}

    validation: &zebra_finch_val
      dataset_name: "zebra_finch_julie_elie"
      split: "val"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "call_type_1"
          override: true
          label_map: {'alarm': 0, 'contact': 1, 'distress': 2, 'nest': 3, 'unknown': 4}

    test: &zebra_finch_test
      dataset_name: "zebra_finch_julie_elie"
      split: "test"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "call_type_1"
          override: true
          label_map: {'alarm': 0, 'contact': 1, 'distress': 2, 'nest': 3, 'unknown': 4}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  - name: "giant_otters_vocalization"
    train:
      dataset_name: "giant_otters"
      split: "test"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "vocalization"
          override: true
          label_map: {'Bark': 0, 'Bark-like vocalization': 1, 'Begging Scream': 2, 'Begging call': 3, 'Begging call-like vocalization': 4, 'Begging scream gradat': 5, 'Close Call': 6, 'Contact Call': 7, 'Contact call gradation': 8, 'Contact call-like vocalization': 9, 'Distress call 1': 10, 'Distress call 2': 11, 'Growl': 12, 'Hah!': 13, 'High whistle': 14, 'Hum': 15, 'Hum gradation': 16, 'Hum gradation-like vocalization': 17, 'Hum short': 18, 'Hum-like vocalization': 19, 'Isolation Call': 20, 'Low whistle': 21, 'Scream Ascending': 22, 'Snort': 23, 'Suckling Call': 24, 'Suckling call': 25, 'Wavering Scream': 26, 'Whine': 27, 'Whistle': 28, 'Whistle Double': 29, 'under water call': 30, 'whine': 31}

    validation:
      dataset_name: "giant_otters"
      split: "test"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "vocalization"
          override: true
          label_map: {'Bark': 0, 'Bark-like vocalization': 1, 'Begging Scream': 2, 'Begging call': 3, 'Begging call-like vocalization': 4, 'Begging scream gradat': 5, 'Close Call': 6, 'Contact Call': 7, 'Contact call gradation': 8, 'Contact call-like vocalization': 9, 'Distress call 1': 10, 'Distress call 2': 11, 'Growl': 12, 'Hah!': 13, 'High whistle': 14, 'Hum': 15, 'Hum gradation': 16, 'Hum gradation-like vocalization': 17, 'Hum short': 18, 'Hum-like vocalization': 19, 'Isolation Call': 20, 'Low whistle': 21, 'Scream Ascending': 22, 'Snort': 23, 'Suckling Call': 24, 'Suckling call': 25, 'Wavering Scream': 26, 'Whine': 27, 'Whistle': 28, 'Whistle Double': 29, 'under water call': 30, 'whine': 31}

    test:
      dataset_name: "giant_otters"
      split: "test"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "vocalization"
          override: true
          label_map: {'Bark': 0, 'Bark-like vocalization': 1, 'Begging Scream': 2, 'Begging call': 3, 'Begging call-like vocalization': 4, 'Begging scream gradat': 5, 'Close Call': 6, 'Contact Call': 7, 'Contact call gradation': 8, 'Contact call-like vocalization': 9, 'Distress call 1': 10, 'Distress call 2': 11, 'Growl': 12, 'Hah!': 13, 'High whistle': 14, 'Hum': 15, 'Hum gradation': 16, 'Hum gradation-like vocalization': 17, 'Hum short': 18, 'Hum-like vocalization': 19, 'Isolation Call': 20, 'Low whistle': 21, 'Scream Ascending': 22, 'Snort': 23, 'Suckling Call': 24, 'Suckling call': 25, 'Wavering Scream': 26, 'Whine': 27, 'Whistle': 28, 'Whistle Double': 29, 'under water call': 30, 'whine': 31}

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]

  - name: "bengalese_finch_repertoire_bird2"
    train:  # Dummy train set (using test set for compatibility)
      dataset_name: "Bengalese Finch Calls"
      split: "Bird2_train_small"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "call_type"
          override: true
          label_map: {"0": 0, "1": 1, "2": 2, "3": 3, "4": 4, "5": 5, "6": 6, "7": 7, "8": 8, "9": 9, "a": 10, "b": 11, "c": 12, "d": 13, "e": 14, "f": 15, "g": 16}

    validation:  # Dummy validation set (using test set for compatibility)
      dataset_name: "Bengalese Finch Calls"
      split: "Bird2_valid"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "call_type"
          override: true
          label_map: {"0": 0, "1": 1, "2": 2, "3": 3, "4": 4, "5": 5, "6": 6, "7": 7, "8": 8, "9": 9, "a": 10, "b": 11, "c": 12, "d": 13, "e": 14, "f": 15, "g": 16}

    test:
      dataset_name: "Bengalese Finch Calls"
      split: "Bird2_test"
      sample_rate: 16000
      transformations:
        - type: "label_from_feature"
          feature: "call_type"
          override: true
          label_map: {"0": 0, "1": 1, "2": 2, "3": 3, "4": 4, "5": 5, "6": 6, "7": 7, "8": 8, "9": 9, "a": 10, "b": 11, "c": 12, "d": 13, "e": 14, "f": 15, "g": 16}

    metrics: ["accuracy", "clustering_ari", "clustering_nmi"]

  # # =====================================================
  # # VFPA KILLER WHALE VOCAL REPERTOIRE CLASSIFICATION
  # # =====================================================

  - name: "vfpa_srkw_call_types"
    train:
      dataset_name: "vfpa_killer_whales"
      split: "srkw_standard"
      sample_rate: 16000
      data_root: "../esp-data/dclde_2026_killer_whales/vfpa/"
      transformations:
        - type: "label_from_feature"
          feature: "call_type"
          override: true
          # Actual SRKW call types from the srkw_standard dataset (27 unique types, 1,336 samples)
          label_map: {
            'S01': 0, 'S02i': 1, 'S02ii': 2, 'S02iii': 3, 'S03': 4, 'S04': 5, 'S05': 6, 'S06': 7, 'S07': 8, 'S08i': 9,
            'S08ii': 10, 'S10': 11, 'S12': 12, 'S13i': 13, 'S14': 14, 'S16': 15, 'S17': 16, 'S18': 17, 'S19': 18, 'S22': 19,
            'S32': 20, 'S36': 21, 'S37i': 22, 'S37ii': 23, 'S41': 24, 'S42': 25, 'S44': 26
          }

    validation:
      dataset_name: "vfpa_killer_whales"
      split: "srkw_standard"  # Use same as train - will be split internally if needed
      sample_rate: 16000
      data_root: "../esp-data/dclde_2026_killer_whales/vfpa/"
      transformations:
        - type: "label_from_feature"
          feature: "call_type"
          override: true
          label_map: {
            'S01': 0, 'S02i': 1, 'S02ii': 2, 'S02iii': 3, 'S03': 4, 'S04': 5, 'S05': 6, 'S06': 7, 'S07': 8, 'S08i': 9,
            'S08ii': 10, 'S10': 11, 'S12': 12, 'S13i': 13, 'S14': 14, 'S16': 15, 'S17': 16, 'S18': 17, 'S19': 18, 'S22': 19,
            'S32': 20, 'S36': 21, 'S37i': 22, 'S37ii': 23, 'S41': 24, 'S42': 25, 'S44': 26
          }

    test:
      dataset_name: "vfpa_killer_whales"
      split: "srkw_standard"
      sample_rate: 16000
      data_root: "../esp-data/dclde_2026_killer_whales/vfpa/"
      transformations:
        - type: "label_from_feature"
          feature: "call_type"
          override: true
          label_map: {
            'S01': 0, 'S02i': 1, 'S02ii': 2, 'S02iii': 3, 'S03': 4, 'S04': 5, 'S05': 6, 'S06': 7, 'S07': 8, 'S08i': 9,
            'S08ii': 10, 'S10': 11, 'S12': 12, 'S13i': 13, 'S14': 14, 'S16': 15, 'S17': 16, 'S18': 17, 'S19': 18, 'S22': 19,
            'S32': 20, 'S36': 21, 'S37i': 22, 'S37ii': 23, 'S41': 24, 'S42': 25, 'S44': 26
          }

    metrics: ["accuracy", "multiclass_f1", "clustering_ari", "clustering_nmi", "clustering_v_measure", "clustering_silhouette"]
