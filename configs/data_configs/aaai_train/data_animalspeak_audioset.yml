# Configuration that concatenates AnimalSpeak with AudioSet during training
# - Training: AnimalSpeak + AudioSet (concatenated)
# - Validation: AnimalSpeak only
# - Both use 16kHz sample rate and unified column mappings
# - Option B: Global label transforms applied after concatenation to avoid collisions

train_datasets:
  # AnimalSpeak dataset for training (keep original canonical_name field)
  - dataset_name: animalspeak
    dataset_version: 0.0
    split: train
    balance: false
    balance_attribute: canonical_name
    custom_balancing: false
    balancing_method: upsample
    subset_percentage: 1.0
    audio_max_length_seconds: 10
    audio_path_col: path
    # data_root: ../../milad_earthspecies_org/data-migration/marius-highmem/mnt/foundation-model-data/audio_16k/
    data_root: /scratch-representation-learning/
    # data_root: gs://foundation-model-data/audio_16k/
    sample_rate: 16000
    # NO label transformations here - keep original canonical_name field

    # transformations:
    #   - type: filter
    #     mode: exclude
    #     property: canonical_name
    #     values: [""]
    #   - type: filter
    #     mode: exclude
    #     property: source
    #     values: ["AudioCaps", "WavCaps", "wavcaps", "audiocaps", "audio_caps", "Audiocaps"]

  # AudioSet dataset for training (keep original labels field)
  - dataset_name: audioset
    split: train
    sample_rate: 16000
    # data_root: gs://esp-ml-datasets/audioset/v0.1.0/raw/
    # data_root: gs://esp-ml-datasets/audioset/v0.1.0/raw/
    # data_root: ../esp-data/audioset/v0.1.0/raw/
    data_root: /scratch-representation-learning/audioset/v0.1.0/raw/
    # NO transformations here - keep original labels field

val_datasets:
  # Only use AnimalSpeak for validation (keep original canonical_name field)
  - dataset_name: animalspeak
    dataset_version: 0.0
    split: validation
    balance: false
    balance_attribute: canonical_name
    custom_balancing: false
    balancing_method: upsample
    subset_percentage: 1.0
    audio_max_length_seconds: 10
    audio_path_col: path
    data_root: /scratch-representation-learning/
    # data_root: ../../milad_earthspecies_org/data-migration/marius-highmem/mnt/foundation-model-data/audio_16k/
    sample_rate: 16000
    transformations:
      - type: labels_from_features
        features: [canonical_name]
        output_feature: label
        override: true

# Concatenation settings
concatenate_train: true
concatenate_val: true
concatenate_method: soft

# Global transformations applied AFTER concatenation
transformations:
  - type: labels_from_features
    features: [labels]
    output_feature: label
    override: true

  - type: deduplicate
    subset: ['local_path']
