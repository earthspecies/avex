# Configuration that concatenates AnimalSpeak with AudioSet during training
# - Training: AnimalSpeak + AudioSet (concatenated)
# - Validation: AnimalSpeak only
# - Both use 16kHz sample rate and unified column mappings
# - Option B: Global label transforms applied after concatenation to avoid collisions

train_datasets:
  # AnimalSpeak dataset for training (keep original canonical_name field)
  - dataset_name: animalspeak
    dataset_version: 0.0
    split: train
    balance: false
    balance_attribute: canonical_name
    custom_balancing: false
    balancing_method: upsample
    subset_percentage: 1.0
    audio_max_length_seconds: 10
    audio_path_col: path
    data_root: ../../milad_earthspecies_org/data-migration/marius-highmem/mnt/foundation-model-data/audio_16k/
    sample_rate: 16000
    transformations:
      - type: require_features
        # Drop rows where canonical_name is missing or empty
        features: [canonical_name]
        mode: exclude

  # AudioSet dataset for training (keep original labels field)
  # - dataset_name: audioset
  #   split: train
  #   sample_rate: 16000
  #   # data_root: gs://esp-ml-datasets/audioset/v0.1.0/raw/
  #   data_root: ../esp-data/audioset/v0.1.0/raw/
  #   # NO transformations here - keep original labels field

val_datasets:
  # Only use AnimalSpeak for validation (keep original canonical_name field)
  - dataset_name: animalspeak
    dataset_version: 0.0
    split: validation
    balance: false
    balance_attribute: canonical_name
    custom_balancing: false
    balancing_method: upsample
    subset_percentage: 1.0
    audio_max_length_seconds: 10
    audio_path_col: path
    data_root: ../../milad_earthspecies_org/data-migration/marius-highmem/mnt/foundation-model-data/audio_16k/
    sample_rate: 16000
    # transformations:
    #   # Drop rows without a canonical_name in the validation split as well
    #   - type: filter
    #     property: canonical_name
    #     values: [""]
    #     mode: exclude

# Concatenation settings
concatenate_train: true
concatenate_val: true
concatenate_method: soft

# Global transformations applied AFTER concatenation
transformations:
  # Generate human-readable captions for CLIP/CLAP training
  - type: text_label_from_features
    features: [caption, caption2, species_common, canonical_name, taxonomic_name]
    output_feature: text_label
    listify: true
    override: true

  - type: deduplicate
    subset: ['local_path']
