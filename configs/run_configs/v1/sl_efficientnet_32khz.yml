---
# Model configuration
model_spec:
  name: efficientnet
  pretrained: true
  audio_config:
    sample_rate: 32000
    n_fft: 800
    hop_length: 160
    win_length: 800
    window: hann
    n_mels: 256
    representation: mel_spectrogram
    normalize: true
    target_length_seconds: 10
    window_selection: random
    use_peak_extraction: false
    # peak_extraction_prob: 0.2
    # peak_min_length_seconds: 0.1
    # peak_merge_gap_seconds: 0.3
    # activity_energy_threshold_db: -30.0  # For RMS method (fallback)
    # # PCEN-based peak detection (noise-robust)
    # peak_detection_method: pcen  # Options: "rms" (simple) or "pcen" (noise-robust)
    # pcen_threshold_percentile: 60.0  # Higher = more selective (0-100)
    # pcen_n_fft: 2048
    # pcen_n_mels: 128
    # pcen_gain: 0.98
    # pcen_bias: 2.0
    # pcen_power: 0.5
    # pcen_time_constant: 0.4
    # peak_top_k: 5  # Only select from top-5 peaks by energy (null = use all peaks)

dataset_config: configs/data_configs/aaai_train/data_animalspeak.yml
# dataset_config: configs/data_configs/data_base.yml

# How to use the labels (supervised: use class indices, text: use text labels)
label_type: supervised
debug_mode: false

# audio preprocessing (e.g. event detection)
preprocessing: null

# Target sampleâ€‘rate expected by the model (must match audio_config.sample_rate)
sr: 32000


# Log training runs to MLflow
logging: wandb
output_dir: "./runs/aaai/efficientnet_animalspeak"

training_params:
  train_epochs: 50
  lr: 0.0005
  batch_size: 32
  optimizer: adamw8bit
  weight_decay: 0.01
  amp: true
  amp_dtype: bf16

# Learning rate scheduler configuration
scheduler:
  name: cosine
  warmup_steps: 4000
  min_lr: 1e-6


augmentations:
  # Add background noise at random SNRs
  - noise:
      noise_dirs:
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/demand_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/idmt"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/tut2016_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/urbansound"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/freesound_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/\
          orcasound_shipnoise_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/deepship_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/shipsear_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/wham_noise"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/audioset"
        # - "/scratch-representation-learning/noise_16k/ssw-detection"
      snr_db_range: [-5, 20]  # mix noise between -5 dB and 20 dB SNR
      augmentation_prob: 0.5
      mask_signal_prob: 0.05
    # Mixup augmentation for audio samples
  - mixup:
      alpha: 0.4  # Controls the Beta distribution shape
      n_mixup: 1  # Maximum number of mixup pairs per batch (defaults to 1)
      augmentation_prob: 0.5  # Probability of applying mixup to a batch


# Cross entropy loss for classification
loss_function: bce

device: cuda

seed: 42

num_workers: 12

run_name: efficientnet_base

wandb_project: representation_learning
multilabel: true
metrics: ["accuracy"]

clustering_eval:
  enabled: false
  frequency: 1  # Every epoch
  layers: "last_layer"
  use_validation_set: true
  # max_samples: 1000  # Limit samples for performance
  run_before_training: true  # Run before first epoch
