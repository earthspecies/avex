---
# BEATs backbone for audio classification (masked pooling + linear head)
model_spec:
  name: beats
  pretrained: false  # Set to true when loading pretrained BEATs weights
  device: cuda
  audio_config:  # Still define for completeness; BEATs does its own Fbank conversion
    sample_rate: 32000
    representation: raw  # BEATs expects raw waveform
    normalize: false
    target_length_seconds: 10
    window_selection: random
    # Activity detection for selecting windows from active regions (e.g., bird calls)
    use_peak_extraction: false
    # peak_extraction_prob: 0.1
    # peak_min_length_seconds: 0.1
    # peak_merge_gap_seconds: 0.3
    # activity_energy_threshold_db: -30.0  # More selective for cleaner separation

# Dataset configuration (path to a valid dataset config)
dataset_config: configs/data_configs/v1/data_bio_nfs.yml
# Output directory for checkpoints and logs
output_dir: "./runs/v1/sl_newbeats"
multilabel: true
label_type: supervised
run_name: sl_beats_bio  # should be sl_beats_bio
# audio preprocessing (none â€“ handled inside the model)
preprocessing: null

# Target sample-rate expected by the model
sr: 32000
debug_mode: false
# Log training runs to MLflow
logging: wandb

# Path to checkpoint to resume from (set to null or a path)
# Note: This expects a FULL training checkpoint (model + optimizer + scheduler + epoch)
resume_from_checkpoint: nulll
# resume_from_checkpoint: runs/v1/sl_newbeats/2026-01-11_11-41-47/checkpoint_epoch_002.pt
# resume_from_checkpoint: runs/v1/sl_newbeats/2026-01-02_05-42-28/checkpoint_epoch_001.pt
# runs/aaai/sl_beats_animalspeak_audioset/2025-07-16_02-50-45/checkpoint_epoch_001.pt

# Path to pretrained encoder checkpoint (encoder weights only, starts training fresh)
# Use this for loading a BEATs encoder checkpoint without the classification head
# Supports BEATs format ({"cfg":..., "model":...}) and training checkpoints
pretrain_encoder_checkpoint: gs://representation-learning/models/beats_pretrain/32khz_iter2_e13_mapped.pt

training_params:
  train_epochs: 100
  lr: 0.0005
  batch_size: 16  # Reduced from 48 to avoid OOM during unfrozen backward pass
  optimizer: adamw8bit
  weight_decay: 0.01
  amp: true
  amp_dtype: bf16
  freeze_backbone_epochs: 2
  second_stage_lr: 0.0001
  second_stage_warmup_steps: 5000
  skip_validation: false

# Learning rate scheduler configuration
scheduler:
  name: cosine
  warmup_steps: 5000
  min_lr: 1e-6

augmentations:
  # Add background noise at random SNRs
  - noise:
      noise_dirs:
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/demand_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/idmt"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/tut2016_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/urbansound"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/freesound_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/\
          orcasound_shipnoise_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/deepship_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/shipsear_10s"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/wham_noise"
        - "/home/milad_earthspecies_org/data-migration/lambda/home/ubuntu/\
          foundation-model-storage/foundation-model-data/audio_16k/noise/audioset"
        # - "/scratch-representation-learning/noise_16k/ssw-detection"
      snr_db_range: [-5, 20]  # mix noise between -5 dB and 20 dB SNR
      augmentation_prob: 0.5
      mask_signal_prob: 0.05
    # Mixup augmentation for audio samples
  - mixup:
      alpha: 0.4  # Controls the Beta distribution shape
      n_mixup: 1  # Maximum number of mixup pairs per batch (defaults to 1)
      augmentation_prob: 0.5  # Probability of applying mixup to a batch

# Loss for classification
loss_function: bce

# General settings
seed: 13
num_workers: 12
wandb_project: representation_learning
