---
# OpenBEATs backbone for audio classification (mean pooling + linear head)
# Fine-tuning from HuggingFace pretrained checkpoints
#
# Available pretrained checkpoints:
#   - openbeats-base-i1, openbeats-base-i2, openbeats-base-i3 (~90M parameters)
#   - openbeats-large-i1, openbeats-large-i2, openbeats-large-i3 (~317M parameters)
#
# To use a pretrained checkpoint, set:
#   - pretrained: true
#   - model_id: <checkpoint_name> (e.g., "openbeats-large-i2")
#   - model_size: base or large (auto-detected from model_id if available)
model_spec:
  name: openbeats
  pretrained: true
  model_id: "openbeats-large-i2"  # HuggingFace checkpoint to load
  model_size: "large"             # base (~90M), large (~317M), giant (~1B), titan (~1.9B)
  use_flash_attn: true            # Enable flash attention (requires PyTorch >= 2.0)
  device: cuda
  audio_config:
    sample_rate: 16000
    representation: raw             # OpenBEATs expects raw waveform
    normalize: false
    target_length_seconds: 10
    window_selection: random

# Dataset configuration
dataset_config: configs/data_configs/data_base.yml

# Output directory for checkpoints and logs
output_dir: "./runs/openbeats_ft"
run_name: openbeats_ft_large
label_type: supervised

# Audio preprocessing (none â€“ handled inside the model)
preprocessing: null

# Target sample rate expected by the model
sr: 16000
debug_mode: false

# Log training runs to MLflow
logging: wandb

# Path to checkpoint to resume from (set to null or a path)
resume_from_checkpoint: null

training_params:
  train_epochs: 20
  lr: 0.0001
  batch_size: 32
  optimizer: adamw
  weight_decay: 0.01
  amp: true
  amp_dtype: bf16

# Learning rate scheduler configuration
scheduler:
  name: cosine
  warmup_steps: 500
  min_lr: 1e-6

# Loss for classification
loss_function: cross_entropy

# General settings
seed: 42
num_workers: 4

# W&B logging (optional)
wandb_project: representation_learning

# Optional: uncomment to freeze backbone for first N epochs (two-stage training)
# freeze_backbone_epochs: 2
