# On which datasets to run the evaluation and which metrics to use
dataset_config: configs/data_configs/benchmark.yml

training_params:
  train_epochs: 50
  lr: 0.001
  batch_size: 32
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16
  gradient_clip_val: 1.0
  warmup_epochs: 5
  scheduler_type: cosine

# Which experiments to evaluate
experiments:
  - run_name: sl_beats_animalspeak_attention_last
    run_config: configs/run_configs/pretrained/beats_ft.yml
    probe_config:
      probe_type: attention
      aggregation: none
      input_processing: sequence
      target_layers: ["last_layer"]
      num_heads: 8
      attention_dim: 64
      num_layers: 1
      max_sequence_length: 800
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: true
    pretrained: false
    checkpoint_path: gs://representation-learning/models/sl_beats_animalspeak.pt

  - run_name: sl_beats_animalspeak_attention_all
    run_config: configs/run_configs/pretrained/beats_ft.yml
    probe_config:
      probe_type: attention
      aggregation: none
      input_processing: sequence
      target_layers: ["all"]
      num_heads: 8
      attention_dim: 64
      num_layers: 1
      max_sequence_length: 800
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: true
    pretrained: false
    checkpoint_path: gs://representation-learning/models/sl_beats_animalspeak.pt

  - run_name: sl_beats_animalspeak_attention_ft
    run_config: configs/run_configs/pretrained/beats_ft.yml
    probe_config:
      probe_type: attention
      aggregation: none
      input_processing: sequence
      target_layers: ["last_layer"]
      num_heads: 8
      attention_dim: 64
      num_layers: 1
      max_sequence_length: 800
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: false
      online_training: true
    pretrained: false
    checkpoint_path: gs://representation-learning/models/sl_beats_animalspeak.pt

  - run_name: sl_beats_animalspeak_linear_last
    run_config: configs/run_configs/pretrained/beats_ft.yml
    probe_config:
      probe_type: linear
      aggregation: mean
      input_processing: pooled
      target_layers: ["last_layer"]
      freeze_backbone: true
      online_training: true
    pretrained: false
    checkpoint_path: gs://representation-learning/models/sl_beats_animalspeak.pt

  - run_name: sl_beats_animalspeak_linear_all
    run_config: configs/run_configs/pretrained/beats_ft.yml
    probe_config:
      probe_type: linear
      target_layers: ["all"]
      aggregation: mean
      input_processing: pooled
      freeze_backbone: true
      online_training: true
    pretrained: false
    checkpoint_path: gs://representation-learning/models/sl_beats_animalspeak.pt

  - run_name: sl_beats_animalspeak_linear_ft
    run_config: configs/run_configs/pretrained/beats_ft.yml
    probe_config:
      probe_type: linear
      aggregation: mean
      input_processing: pooled
      target_layers: ["last_layer"]
      freeze_backbone: false
      online_training: true
    pretrained: false
    checkpoint_path: gs://representation-learning/models/sl_beats_animalspeak.pt

  # - run_name: sl_beats_animalspeak_lstm_all
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "lstm"
  #     aggregation: "none"
  #     input_processing: "sequence"
  #     target_layers: ["all"]
  #     lstm_hidden_size: 64
  #     num_layers: 1
  #     bidirectional: true
  #     max_sequence_length: 1000
  #     use_positional_encoding: false
  #     dropout_rate: 0.3
  #     freeze_backbone: true
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

  # - run_name: sl_beats_animalspeak_lstm_last
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "lstm"
  #     aggregation: "none"
  #     input_processing: "sequence"
  #     target_layers: ["last_layer"]
  #     lstm_hidden_size: 64
  #     num_layers: 1
  #     bidirectional: true
  #     max_sequence_length: 1000
  #     use_positional_encoding: false
  #     dropout_rate: 0.3
  #     freeze_backbone: true
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

  # - run_name: sl_beats_animalspeak_lstm_ft
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "lstm"
  #     aggregation: "none"
  #     input_processing: "sequence"
  #     target_layers: ["last_layer"]
  #     lstm_hidden_size: 64
  #     num_layers: 1
  #     bidirectional: true
  #     max_sequence_length: 1000
  #     use_positional_encoding: false
  #     dropout_rate: 0.3
  #     freeze_backbone: false
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

  # - run_name: sl_beats_animalspeak_mlp_all
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "mlp"
  #     aggregation: "mean"
  #     input_processing: "pooled"
  #     target_layers: ["all"]
  #     hidden_dims: [512, 256]
  #     dropout_rate: 0.3
  #     activation: "gelu"
  #     freeze_backbone: true
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

  # - run_name: sl_beats_animalspeak_mlp_last
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "mlp"
  #     aggregation: "mean"
  #     input_processing: "pooled"
  #     target_layers: ["last_layer"]
  #     hidden_dims: [512, 256]
  #     dropout_rate: 0.3
  #     activation: "gelu"
  #     freeze_backbone: true
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

  # - run_name: sl_beats_animalspeak_mlp_ft
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "mlp"
  #     aggregation: "mean"
  #     input_processing: "pooled"
  #     target_layers: ["last_layer"]
  #     hidden_dims: [512, 256]
  #     dropout_rate: 0.3
  #     activation: "gelu"
  #     freeze_backbone: false
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

  # - run_name: sl_beats_animalspeak_transformer_all
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "transformer"
  #     aggregation: "none"
  #     input_processing: "sequence"
  #     target_layers: ["all"]
  #     num_heads: 8
  #     attention_dim: 128
  #     num_layers: 1
  #     max_sequence_length: 1200
  #     use_positional_encoding: false
  #     dropout_rate: 0.3
  #     freeze_backbone: true
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

  # - run_name: sl_beats_animalspeak_transformer_last
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "transformer"
  #     aggregation: "none"
  #     input_processing: "sequence"
  #     target_layers: ["last_layer"]
  #     num_heads: 8
  #     attention_dim: 128
  #     num_layers: 1
  #     max_sequence_length: 1200
  #     use_positional_encoding: false
  #     dropout_rate: 0.3
  #     freeze_backbone: true
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

  # - run_name: sl_beats_animalspeak_transformer_ft
  #   run_config: configs/run_configs/pretrained/beats_ft.yml
  #   probe_config:
  #     probe_type: "transformer"
  #     aggregation: "none"
  #     input_processing: "sequence"
  #     target_layers: ["last_layer"]
  #     num_heads: 8
  #     attention_dim: 128
  #     num_layers: 1
  #     max_sequence_length: 1200
  #     use_positional_encoding: false
  #     dropout_rate: 0.3
  #     freeze_backbone: false
  #     online_training: true
  #   pretrained: false
  #   checkpoint_path: gs://representation-learning/models/sl_beats_all.pt

# Where to save the evaluation results
save_dir: evaluation_results/icassp/sl_beats_animalspeak

# Optional: Append results to a global CSV file for cross-model comparison
results_csv_path: evaluation_results/icassp/all_models_results.csv

device: cuda

seed: 42

num_workers: 8  # Enable workers for better memory management

# Evaluation phases
eval_modes:
  - probe

offline_embeddings:
  overwrite_embeddings: true

# Control tqdm progress bar verbosity during fine-tuning
# Set to true to disable progress bars and reduce output verbosity
disable_tqdm: true
