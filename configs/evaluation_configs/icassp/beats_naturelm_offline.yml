# On which datasets to run the evaluation and which metrics to use
dataset_config: configs/data_configs/benchmark.yml

training_params:
  train_epochs: 10
  lr: 0.001
  batch_size: 32
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16
  gradient_clip_val: 1.0
  warmup_epochs: 5
  scheduler_type: cosine

# Which experiments to evaluate
experiments:
  - run_name: beats_naturelm_attention_last
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: attention
      aggregation: none
      input_processing: sequence
      target_layers: ["last_layer"]
      num_heads: 8
      attention_dim: 64
      num_layers: 1
      max_sequence_length: 800
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_attention_all
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: attention
      aggregation: none
      input_processing: sequence
      target_layers: ["all"]
      num_heads: 8
      attention_dim: 64
      num_layers: 1
      max_sequence_length: 800
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_linear_last
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: linear
      aggregation: mean
      input_processing: pooled
      target_layers: ["last_layer"]
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_linear_all
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: linear
      target_layers: ["all"]
      aggregation: mean
      input_processing: pooled
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_lstm_all
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: "lstm"
      aggregation: "none"
      input_processing: "sequence"
      target_layers: ["all"]
      lstm_hidden_size: 64
      num_layers: 1
      bidirectional: true
      max_sequence_length: 1000
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_lstm_last
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: "lstm"
      aggregation: "none"
      input_processing: "sequence"
      target_layers: ["last_layer"]
      lstm_hidden_size: 64
      num_layers: 1
      bidirectional: true
      max_sequence_length: 1000
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_mlp_all
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: "mlp"
      aggregation: "mean"
      input_processing: "pooled"
      target_layers: ["all"]
      hidden_dims: [512, 256]
      dropout_rate: 0.3
      activation: "gelu"
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_mlp_last
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: "mlp"
      aggregation: "mean"
      input_processing: "pooled"
      target_layers: ["last_layer"]
      hidden_dims: [512, 256]
      dropout_rate: 0.3
      activation: "gelu"
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_transformer_all
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: "transformer"
      aggregation: "none"
      input_processing: "sequence"
      target_layers: ["all"]
      num_heads: 8
      attention_dim: 128
      num_layers: 1
      max_sequence_length: 1200
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: false
    pretrained: true

  - run_name: beats_naturelm_transformer_last
    run_config: configs/run_configs/pretrained/beats_naturelm.yml
    probe_config:
      probe_type: "transformer"
      aggregation: "none"
      input_processing: "sequence"
      target_layers: ["last_layer"]
      num_heads: 8
      attention_dim: 128
      num_layers: 1
      max_sequence_length: 1200
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: false
    pretrained: true


# Where to save the evaluation results
save_dir: evaluation_results/icassp/beats_naturelm

# Optional: Append results to a global CSV file for cross-model comparison
results_csv_path: evaluation_results/icassp/all_models_results.csv

device: cuda

seed: 42

num_workers: 8  # Enable workers for better memory management

# Evaluation phases
eval_modes:
  - retrieval
  - clustering

# Control tqdm progress bar verbosity during fine-tuning
# Set to true to disable progress bars and reduce output verbosity
disable_tqdm: true

offline_embeddings:
  overwrite_embeddings: false
  use_streaming_embeddings: true
  memory_limit_gb: 32
  streaming_chunk_size: 1000
  hdf5_compression: gzip
  hdf5_compression_level: 4
  auto_chunk_size: true
  max_chunk_size: 2000
  min_chunk_size: 100
  batch_chunk_size: 10
  cache_size_limit_gb: 8.0
