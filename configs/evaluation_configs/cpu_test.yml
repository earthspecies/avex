# On which datasets to run the evaluation and which metrics to use
dataset_config: configs/data_configs/benchmark_single.yml

training_params:
  train_epochs: 10
  lr: 0.0003
  batch_size: 16
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16


# Which experiments to evaluate
# TODO: all checkpoints to be gs paths and uploaded during train
experiments:
  - run_name: efficientnet_frozen_test
    run_config: configs/run_configs/efficientnet_base_test.yml
    ### whether to use pretrained model or the one we train on bioacoustic data
    pretrained: true
    probe_config:
      type: linear
      target_layers: ["model.avgpool"]
      aggregation: "mean"
      input_processing: "pooled"
      freeze_backbone: true
      online_training: false

  # - run_name: eat_pretrain_og
  #   run_config: configs/run_configs/eat_pretrain_og.yml
  #   ### which layers to probe for embeddings
  #   layers: last_layer
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   checkpoint_path: runs/eat_pretrain_bf16/checkpoints/checkpoint_epoch_002_old.pt
  #   # checkpoint_path: runs/eat_pretrain/checkpoints/checkpoint_epoch_005.pt
  #   pretrained: false

  # - run_name: eat_pretrain
  #   run_config: configs/run_configs/eat_pretrain.yml
  #   ### which layers to probe for embeddings
  #   layers: last_layer
  #   checkpoint_path: runs/eat_pretrain_bf16_25_05_nopad/checkpoints/checkpoint_epoch_001.pt
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   # checkpoint_path: runs/eat_pretrain_bf16_25_05/checkpoints/checkpoint_epoch_001.pt
  #   # checkpoint_path: runs/eat_pretrain_bf16_25_05_nopad/checkpoints/checkpoint_epoch_001.pt
  #   # checkpoint_path: runs/eat_pretrain/checkpoints/checkpoint_epoch_005.pt
  #   pretrained: false

  # - run_name: clap
  #   run_config: configs/run_configs/clip_base_beans.yml
  #   ### which layers to probe for embeddings
  #   layers: audio_projection
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   checkpoint_path: runs/clip_baseline_19_05/checkpoints/checkpoint_epoch_018.pt


  # - run_name: clap_linear_probe_beans
  #   run_config: configs/run_configs/clip_base_beans.yml
  #   ### which layers to probe for embeddings
  #   layers: audio_projection
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   pretrained: false
  #   checkpoint_path: ~/representation-learning/runs/clip_baseline_13_05/checkpoints/checkpoint_epoch_050.pt

  # - run_name: beats
  #   run_config: configs/run_configs/beats_base.ymlx
  #   ### which layers to probe for embeddings
  #   layers: backbone
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   pretrained: false

# Where to save the evaluation results
save_dir: evaluation_results/integration_test

device: cpu

seed: 42

num_workers: 0  # Enable workers for better memory management


# Evaluation phases
eval_modes:
  - probe
  - retrieval

overwrite_embeddings: true
