# On which datasets to run the evaluation and which metrics to use
dataset_config: configs/data_configs/benchmark_single.yml

training_params:
  train_epochs: 30
  lr: 0.001
  batch_size: 64
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16

# experiments:
#   - run_name: birdnet_base
#     run_config: configs/run_configs/pretrained/birdnet.yml
#     checkpoint_path: null  # use pretrained TF-Hub weights
#     pretrained: true
#     probe_config:
#       probe_type: "linear"
#       aggregation: "mean"
#       input_processing: "pooled"
#       target_layers: ["last_layer"]
#       freeze_backbone: true
#       online_training: false

# Which experiments to evaluate
experiments:
  - run_name: efficientnet_animalspeak_new
    run_config: configs/run_configs/aaai_train/sl_efficientnet_animalspeak.yml
    ### whether to use pretrained model or the one we train on bioacoustic data
    pretrained: false
    checkpoint_path: gs://representation-learning/models/efficientnet_animalspeak.pt
    ### probe configuration for consistent embedding handling
    probe_config:
      # probe_type: "mlp"
      # aggregation: "mean"
      # input_processing: "pooled"
      # target_layers: ["model.avgpool"]
      # freeze_backbone: false
      # online_training: true
      # hidden_dims: [512, 256]
      # dropout_rate: 0.3
      # activation: "gelu"
      #
      # probe_type: "linear"
      # aggregation: "mean"
      # input_processing: "pooled"
      # target_layers: ["model.avgpool"]
      # freeze_backbone: true
      # online_training: true
      #
      # probe_type: "lstm"
      # aggregation: "none"
      # input_processing: "sequence"
      # target_layers: ["model.features.8"]
      # lstm_hidden_size: 16
      # num_layers: 1
      # bidirectional: true
      # max_sequence_length: 1000
      # use_positional_encoding: false
      # dropout_rate: 0.3
      # freeze_backbone: true
      # online_training: true
      #
      probe_type: "attention"
      aggregation: "none"
      input_processing: "sequence"
      target_layers: ["model.features.8"]
      num_heads: 8
      attention_dim: 64
      num_layers: 1
      max_sequence_length: 800
      use_positional_encoding: false
      dropout_rate: 0.3
      freeze_backbone: true
      online_training: true
      #
      # probe_type: "transformer"
      # aggregation: "none"
      # input_processing: "sequence"
      # target_layers: ["model.features.8"]
      # num_heads: 8
      # attention_dim: 128
      # num_layers: 1
      # max_sequence_length: 1200
      # use_positional_encoding: true
      # dropout_rate: 0.3
      # freeze_backbone: true
      # online_training: true

# Streaming embedding extraction configuration
# Enable streaming for memory-efficient extraction when using "all" layers
use_streaming_embeddings: true
streaming_chunk_size: 5000
hdf5_compression: gzip
hdf5_compression_level: 4
auto_chunk_size: true
max_chunk_size: 5000
min_chunk_size: 1000
# Hybrid approach: number of batches to process before writing to disk
# Higher values reduce I/O overhead but use more memory
batch_chunk_size: 100

# Where to save the evaluation results
save_dir: evaluation_results/aaai/efficientnet_animalspeak

# Optional: Append results to a global CSV file for cross-model comparison
results_csv_path: evaluation_results/all_models_results.csv

device: cuda

seed: 42

num_workers: 8  # Enable workers for better memory management

# Evaluation phases
eval_modes:
  - probe
  - retrieval
  - clustering

overwrite_embeddings: true
