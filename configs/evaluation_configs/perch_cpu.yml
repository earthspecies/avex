---
# Evaluate Perch embeddings with linear probe + retrieval on CPU

# Dataset selection
dataset_config: configs/data_configs/benchmark_base.yml  # lightweight bench

# Training params for linear probe (runs on CPU â†’ small batch size)
training_params:
  train_epochs: 10
  lr: 0.001
  batch_size: 16
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16

# Experiments (each entry = one backbone to evaluate)
experiments:
  - run_name: perch_base_cpu
    run_config: configs/run_configs/perch_base_cpu.yml
    layers: last_layer  # special-case handled by PerchModel
    checkpoint_path: null  # use pretrained TF-Hub weights
    pretrained: true
    frozen: true  # Freeze backbone during linear-probe training

# Where to persist evaluation outputs
save_dir: evaluation_results/perch

device: cpu  # Force evaluation loop to stay on CPU

seed: 42
num_workers: 0  # keep single-process I/O for simplicity

# Evaluation modes to execute
eval_modes:
  - probe
  - retrieval
