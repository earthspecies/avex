# On which datasets to run the evaluation and which metrics to use
dataset_config: configs/data_configs/benchmark_base.yml

training_params:
  train_epochs: 100
  lr: 0.0003
  batch_size: 48
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16


# Which experiments to evaluate
#TODO: all checkpoints to be gs paths and uploaded during train
experiments:
  # - run_name: efficientnet_beans
  #   run_config: configs/run_configs/efficientnet_base_beans.yml
  #   ### which layers to probe for embeddings
  #   layers: model.avgpool
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   pretrained: false
  #   checkpoint_path: runs/efficientnet_single_15_05/checkpoints/checkpoint_epoch_029.pt

  # - run_name: eat_pretrain
  #   run_config: configs/run_configs/eat_pretrain.yml
  #   ### which layers to probe for embeddings
  #   layers: last_layer
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   checkpoint_path: runs/eat_pretrain_bf16_25_05_nopad/checkpoints/checkpoint_epoch_003.pt
  #   pretrained: false

  # - run_name: clap
  #   run_config: configs/run_configs/clip_base_beans.yml
  #   ### which layers to probe for embeddings
  #   layers: audio_projection
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   # checkpoint_path: runs/clip_baseline/checkpoints/checkpoint_epoch_059.pt
  #   checkpoint_path: runs/clip_baseline_19_05/checkpoints/checkpoint_epoch_017.pt

  # - run_name: clap_linear_probe_beans
  #   run_config: configs/run_configs/clip_base_beans.yml
  #   ### which layers to probe for embeddings
  #   layers: audio_projection
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   pretrained: false
  #   checkpoint_path: ~/representation-learning/runs/clip_baseline_13_05/checkpoints/checkpoint_epoch_050.pt

  # - run_name: beats
  #   run_config: configs/run_configs/beats_base.yml
  #   ### which layers to probe for embeddings
  #   layers: backbone
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   pretrained: false
  #   checkpoint_path: beats_baseline_full/checkpoints/checkpoint_epoch_005.pt

  - run_name: bird_aves_bio
    run_config: configs/run_configs/aves_base.yml
    ### which layers to probe for embeddings
    layers: last_layer
    ### whether to use pretrained model or the one we train on bioacoustic data
    pretrained: false
    ### path to the checkpoint file

# Where to save the evaluation results
save_dir: evaluation_results/debug

device: cuda

seed: 42

num_workers: 8  # Enable workers for better memory management

# Whether to freeze the backbone (train only the linear probe)
frozen: true

# Evaluation phases
eval_modes:
  - linear_probe
  - retrieval

overwrite_embeddings: true