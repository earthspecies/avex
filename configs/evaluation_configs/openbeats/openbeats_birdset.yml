# OpenBEATs BirdSet Benchmark Evaluation
# =======================================
# Evaluates OpenBEATs on BirdSet Detection tasks
#
# Metrics from the paper:
#   - BirdSet: Probe (mAP), R-AUC (retrieval)
#
# Usage:
#   uv run repr-learn evaluate --config configs/evaluation_configs/openbeats/openbeats_birdset.yml

dataset_config: configs/data_configs/benchmark_birdset.yml

training_params:
  train_epochs: 900
  lr: 0.001
  batch_size: 32
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16

experiments:
  # OpenBEATs Large i3 (best performing checkpoint)
  - run_name: openbeats_large_i3
    run_config: configs/run_configs/pretrained/openbeats_eval.yml
    pretrained: true
    probe_config:
      probe_type: linear
      target_layers: ["backbone"]
      aggregation: "mean"
      input_processing: "pooled"
      freeze_backbone: true
      online_training: false

save_dir: evaluation_results/openbeats_birdset
results_csv_path: evaluation_results/openbeats_birdset_results.csv

device: cuda
seed: 42
num_workers: 4

eval_modes:
  - probe
  - retrieval

offline_embeddings:
  overwrite_embeddings: true
