# OpenBEATs Individual ID Benchmark Evaluation
# =============================================
# Evaluates OpenBEATs on Individual ID Classification tasks
#
# Individual ID tasks from the paper:
#   - Pipit ID (across year)
#   - Chiffchaff ID (across year)
#   - Macaques ID
#   - Little Owl ID
#
# Metrics from the paper:
#   - Probe accuracy
#   - R-AUC (retrieval)
#
# Usage:
#   uv run repr-learn evaluate --config configs/evaluation_configs/openbeats/openbeats_individual_id.yml

dataset_config: configs/data_configs/individual_id_icassp.yml

training_params:
  train_epochs: 200              # Max epochs (early stopping will terminate earlier)
  lr: 0.01                       # Higher LR for faster convergence with linear probes
  batch_size: 32
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16
  early_stopping_patience: 20    # Stop if no improvement for 20 epochs
  early_stopping_min_delta: 0.001

experiments:
  # OpenBEATs Large i3 (best performing checkpoint)
  - run_name: openbeats_large_i3
    run_config: configs/run_configs/pretrained/openbeats_eval.yml
    pretrained: true
    probe_config:
      probe_type: linear
      target_layers: ["backbone"]
      aggregation: "mean"
      input_processing: "pooled"
      freeze_backbone: true
      online_training: false

save_dir: evaluation_results/openbeats_individual_id
results_csv_path: evaluation_results/openbeats_individual_id_results.csv

device: cuda
seed: 42
num_workers: 4

eval_modes:
  - probe
  - retrieval

offline_embeddings:
  overwrite_embeddings: true
