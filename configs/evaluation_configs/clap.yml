# On which datasets to run the evaluation and which metrics to use
dataset_config: configs/data_configs/benchmark_base.yml

training_params:
  train_epochs: 700
  lr: 0.0007
  batch_size: 32
  optimizer: adamw
  weight_decay: 0.01
  amp: false
  amp_dtype: bf16


# Which experiments to evaluate
# TODO: all checkpoints to be gs paths and uploaded during train
experiments:

  # - run_name: clap
  #   run_config: configs/run_configs/clip_base_beans.yml
  #   ### which layers to probe for embeddings
  #   layers: audio_projection
  #   ### whether to use pretrained model or the one we train on bioacoustic data
  #   # checkpoint_path: runs/clip_baseline/checkpoints/checkpoint_epoch_059.pt
  #   checkpoint_path: runs/clip_baseline_01_06/checkpoints/checkpoint_epoch_014.pt

# Where to save the evaluation results
save_dir: evaluation_results/debug

device: cuda

seed: 42

num_workers: 8  # Enable workers for better memory management

# Evaluation phases
eval_modes:
  # - linear_probe
  - retrieval

overwrite_embeddings: true
