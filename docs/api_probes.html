<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html"><link rel="search" title="Search" href="search.html"><link rel="next" title="Custom Model Registration Guide" href="custom_model_registration.html"><link rel="prev" title="Flexible Probe System" href="probe_system.html">
        <link rel="prefetch" href="_static/logo_light_mode.png" as="image">
        <link rel="prefetch" href="_static/logo_dark_mode.png" as="image">

    <link rel="shortcut icon" href="_static/favicon.svg"><!-- Generated with Sphinx 9.1.0 and Furo 2025.12.19 -->
        <title>Probe API Documentation - Earth Species Project - AVEX Documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=7bdb33bb" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=3b183883" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  --color-brand-primary: #007388;
  --color-brand-content: #007388;
  --color-brand-visited: #7BC4AD;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #5ecad6;
  --color-brand-content: #5ecad6;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #5ecad6;
  --color-brand-content: #5ecad6;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">Earth Species Project - AVEX Documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="_static/logo_light_mode.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="_static/logo_dark_mode.png" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Core Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api_reference.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="supported_models.html">Supported Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Configuration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="training_evaluation.html">Training and Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="embedding_extraction.html">Embedding Extraction and Feature Representations</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="probe_system.html">Flexible Probe System</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Probe API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_model_registration.html">Custom Model Registration Guide</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/earthspecies/avex" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="probe-api-documentation">
<h1>Probe API Documentation<a class="headerlink" href="#probe-api-documentation" title="Link to this heading">¶</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">¶</a></h2>
<p>The probe API provides an interface for <strong>defining, configuring, and attaching probes</strong> to backbone/base models that can be used to adapt or fine-tune the backbone/base models to downstream tasks.</p>
<p><strong>Key Ideas:</strong></p>
<ul class="simple">
<li><p>Probes (and backbone models) are regular PyTorch modules (linear, MLP, LSTM, attention, transformer heads).</p></li>
<li><p>Configuration is done via <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code> (Python) or YAML files that map to <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code>.</p></li>
<li><p>Probes may be trained <strong>online</strong> (attached to a base model) or <strong>offline</strong> (on pre-computed embeddings).</p></li>
</ul>
</section>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Link to this heading">¶</a></h2>
<section id="start-simple">
<h3>1. Start Simple<a class="headerlink" href="#start-simple" title="Link to this heading">¶</a></h3>
<p>Begin with a simple linear probe on the backbone’s last layer:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_probe_from_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbeConfig</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;esp_aves2_naturelm_audio_v1_beats&quot;</span><span class="p">,</span> <span class="n">return_features_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">ProbeConfig</span><span class="p">(</span>
    <span class="n">probe_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="n">target_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;last_layer&quot;</span><span class="p">],</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">freeze_backbone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">online_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">probe</span> <span class="o">=</span> <span class="n">build_probe_from_config</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">base_model</span><span class="o">=</span><span class="n">base</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="increase-complexity-if-needed">
<h3>2. Increase Complexity If Needed<a class="headerlink" href="#increase-complexity-if-needed" title="Link to this heading">¶</a></h3>
<p>If performance plateaus, move to MLP, LSTM, attention, or transformer probes by changing <code class="docutils literal notranslate"><span class="pre">probe_type</span></code> and the related fields in <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code>. Generally, attention probe works best with self-supervised models and transformers and it does not improve much on EfficientNet backbones.</p>
</section>
<section id="match-probe-complexity-to-task">
<h3>3. Match Probe Complexity to Task<a class="headerlink" href="#match-probe-complexity-to-task" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Simple in-domain tasks</strong> → linear probes work well on bird classification/detection tasks because most of the bioacoustics models were trained on this tasks</p></li>
<li><p><strong>Out-of-domain tasks</strong> → attention/transformer probes on all layers or even lower layers work better for repertoire classification or species that were under-represented in the training data used for the backbones.</p></li>
</ul>
</section>
<section id="consider-computational-budget">
<h3>4. Consider Computational Budget<a class="headerlink" href="#consider-computational-budget" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Limited resources</strong> → <code class="docutils literal notranslate"><span class="pre">_last</span></code> variants with linear/MLP</p></li>
<li><p><strong>Generous resources</strong> → <code class="docutils literal notranslate"><span class="pre">_all</span></code> variants with attention/transformer</p></li>
</ul>
</section>
<section id="performance-trade-offs">
<h3>Performance Trade-offs<a class="headerlink" href="#performance-trade-offs" title="Link to this heading">¶</a></h3>
<section id="last-variants">
<h4><code class="docutils literal notranslate"><span class="pre">_last</span></code> Variants<a class="headerlink" href="#last-variants" title="Link to this heading">¶</a></h4>
<p><strong>Pros:</strong></p>
<ul class="simple">
<li><p>Fast execution</p></li>
<li><p>Simple architecture</p></li>
<li><p>Lower memory usage</p></li>
<li><p>Fewer parameters to train</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul class="simple">
<li><p>Single representation, overfitted for species classification (mostly birds) in the case of supervised models</p></li>
<li><p>May miss multi-scale features</p></li>
</ul>
<p><strong>Use when:</strong></p>
<ul class="simple">
<li><p>Quick experiments needed</p></li>
<li><p>Limited computational resources</p></li>
<li><p>Strong, well-trained backbone</p></li>
<li><p>Simple classification tasks</p></li>
</ul>
</section>
<section id="all-variants">
<h4><code class="docutils literal notranslate"><span class="pre">_all</span></code> Variants<a class="headerlink" href="#all-variants" title="Link to this heading">¶</a></h4>
<p><strong>Pros:</strong></p>
<ul class="simple">
<li><p>Rich multi-scale features</p></li>
<li><p>More expressive models</p></li>
<li><p>Better for complex tasks</p></li>
<li><p>Learns optimal layer weighting</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul class="simple">
<li><p>Slower execution</p></li>
<li><p>High disk usage in the case of offline probes</p></li>
<li><p>Higher memory requirements</p></li>
<li><p>More parameters to train</p></li>
</ul>
<p><strong>Use when:</strong></p>
<ul class="simple">
<li><p>Maximum performance needed</p></li>
<li><p>Sufficient computational resources</p></li>
<li><p>Out-of-domain tasks</p></li>
<li><p>Comparing layer-wise representations</p></li>
</ul>
</section>
</section>
<section id="quick-selection-guide">
<h3>Quick Selection Guide<a class="headerlink" href="#quick-selection-guide" title="Link to this heading">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Task Complexity:  LOW ──────────────────────────────────&gt; HIGH
Probe Type:       linear → mlp → lstm → attention → transformer

Feature Scope:    SINGLE LAYER ─────────────────────────&gt; ALL LAYERS
Variant:          _last ─────────────────────────────────&gt; _all

Computational:    FAST ──────────────────────────────────&gt; SLOW
                  linear_last ──────────────────────&gt; transformer_all
</pre></div>
</div>
</section>
</section>
<section id="quick-start">
<h2>Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading">¶</a></h2>
<section id="build-and-use-a-probe-online-mode">
<h3>Build and Use a Probe (Online Mode)<a class="headerlink" href="#build-and-use-a-probe-online-mode" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_probe_from_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbeConfig</span>

<span class="c1"># 1. Load a backbone model that returns features</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;esp_aves2_naturelm_audio_v1_beats&quot;</span><span class="p">,</span> <span class="n">return_features_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># 2. Define a simple linear probe on the backbone features</span>
<span class="n">probe_config</span> <span class="o">=</span> <span class="n">ProbeConfig</span><span class="p">(</span>
    <span class="n">probe_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="n">target_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;backbone&quot;</span><span class="p">],</span>   <span class="c1"># use final backbone layer</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>           <span class="c1"># mean-pool over time</span>
    <span class="n">freeze_backbone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>         <span class="c1"># keep backbone frozen</span>
    <span class="n">online_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>         <span class="c1"># end-to-end graph (even if backbone is frozen)</span>
<span class="p">)</span>

<span class="c1"># 3. Build the probe</span>
<span class="n">probe</span> <span class="o">=</span> <span class="n">build_probe_from_config</span><span class="p">(</span>
    <span class="n">probe_config</span><span class="o">=</span><span class="n">probe_config</span><span class="p">,</span>
    <span class="n">base_model</span><span class="o">=</span><span class="n">base</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="offline-mode-pre-computed-embeddings">
<h3>Offline Mode (Pre-computed Embeddings)<a class="headerlink" href="#offline-mode-pre-computed-embeddings" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_probe_from_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbeConfig</span>

<span class="c1"># For pre-computed embeddings (no base model needed)</span>
<span class="n">probe_config</span> <span class="o">=</span> <span class="n">ProbeConfig</span><span class="p">(</span>
    <span class="n">probe_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="n">target_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;backbone&quot;</span><span class="p">],</span>   <span class="c1"># conceptual; not used when base_model=None</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">freeze_backbone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">online_training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">probe</span> <span class="o">=</span> <span class="n">build_probe_from_config</span><span class="p">(</span>
    <span class="n">probe_config</span><span class="o">=</span><span class="n">probe_config</span><span class="p">,</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>                <span class="c1"># embedding dimension</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Use with embeddings</span>
<span class="c1"># For inference, set the probe to eval mode and use torch.no_grad()</span>
<span class="n">probe</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">probe</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>  <span class="c1"># embeddings shape: (batch, 768)</span>
</pre></div>
</div>
<p><strong>Note:</strong> The probe’s <code class="docutils literal notranslate"><span class="pre">forward()</span></code> method does <strong>not</strong> automatically use inference mode. For inference (when you don’t need gradients), you should:</p>
<ul class="simple">
<li><p>Call <code class="docutils literal notranslate"><span class="pre">probe.eval()</span></code> to set the model to evaluation mode (disables dropout, batch norm updates, etc.)</p></li>
<li><p>Wrap the forward pass in <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">torch.no_grad():</span></code> to disable gradient computation and reduce memory usage</p></li>
</ul>
<p>For training/fine-tuning, use <code class="docutils literal notranslate"><span class="pre">probe.train()</span></code> and omit the <code class="docutils literal notranslate"><span class="pre">torch.no_grad()</span></code> context.</p>
</section>
</section>
<section id="defining-probe-configurations">
<h2>Defining Probe Configurations<a class="headerlink" href="#defining-probe-configurations" title="Link to this heading">¶</a></h2>
<section id="probe-types">
<h3>Probe Types<a class="headerlink" href="#probe-types" title="Link to this heading">¶</a></h3>
<p>Common <code class="docutils literal notranslate"><span class="pre">probe_type</span></code> values:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">linear</span></code> – simple linear classifier</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mlp</span></code> – multi-layer perceptron</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lstm</span></code> – LSTM sequence model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">attention</span></code> – self-attention head</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">transformer</span></code> – transformer encoder probe</p></li>
</ul>
</section>
<section id="core-fields-in-probeconfig">
<h3>Core Fields in <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code><a class="headerlink" href="#core-fields-in-probeconfig" title="Link to this heading">¶</a></h3>
<p>All probe configs support (non-exhaustive):</p>
<ul>
<li><p><strong>Architecture &amp; layers</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">probe_type</span></code>: <code class="docutils literal notranslate"><span class="pre">&quot;linear&quot;</span> <span class="pre">|</span> <span class="pre">&quot;mlp&quot;</span> <span class="pre">|</span> <span class="pre">&quot;lstm&quot;</span> <span class="pre">|</span> <span class="pre">&quot;attention&quot;</span> <span class="pre">|</span> <span class="pre">&quot;transformer&quot;</span></code> - The architecture of the probe head:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;linear&quot;</span></code>: <strong>2D probe</strong> - Simple linear classifier (single fully-connected layer). Fastest and most memory-efficient. Expects 2D input <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">features)</span></code>. Use with <code class="docutils literal notranslate"><span class="pre">aggregation=&quot;mean&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>. Best for: baseline performance, simple tasks, limited resources.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mlp&quot;</span></code>: <strong>2D probe</strong> - Multi-layer perceptron with configurable hidden layers and non-linear activations. More expressive than linear while still efficient. Expects 2D input <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">features)</span></code>. Use with <code class="docutils literal notranslate"><span class="pre">aggregation=&quot;mean&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>. Requires <code class="docutils literal notranslate"><span class="pre">hidden_dims</span></code> parameter. Best for: tasks needing non-linearity, moderate complexity.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;lstm&quot;</span></code>: <strong>3D probe</strong> - Long Short-Term Memory network for sequence modeling. Processes temporal sequences and captures long-range dependencies. Expects 3D input <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">time,</span> <span class="pre">features)</span></code>. Use with <code class="docutils literal notranslate"><span class="pre">aggregation=&quot;none&quot;</span></code> to preserve sequence structure. Requires <code class="docutils literal notranslate"><span class="pre">lstm_hidden_size</span></code>, <code class="docutils literal notranslate"><span class="pre">num_layers</span></code>, and optionally <code class="docutils literal notranslate"><span class="pre">bidirectional</span></code>. Best for: temporal/sequential tasks, variable-length sequences.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;attention&quot;</span></code>: <strong>3D probe</strong> - Self-attention mechanism for sequence modeling. Captures relationships between all positions in a sequence. Expects 3D input <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">time,</span> <span class="pre">features)</span></code>. Use with <code class="docutils literal notranslate"><span class="pre">aggregation=&quot;none&quot;</span></code> to preserve sequence structure. Requires <code class="docutils literal notranslate"><span class="pre">num_heads</span></code> and <code class="docutils literal notranslate"><span class="pre">attention_dim</span></code>. Best for: tasks requiring global sequence understanding, parallel processing.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;transformer&quot;</span></code>: <strong>3D probe</strong> - Full transformer encoder architecture with multiple attention layers. Most expressive and powerful probe type. Expects 3D input <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">time,</span> <span class="pre">features)</span></code>. Use with <code class="docutils literal notranslate"><span class="pre">aggregation=&quot;none&quot;</span></code> to preserve sequence structure. Requires <code class="docutils literal notranslate"><span class="pre">num_heads</span></code>, <code class="docutils literal notranslate"><span class="pre">attention_dim</span></code>, and <code class="docutils literal notranslate"><span class="pre">num_layers</span></code>. Best for: complex tasks, maximum performance, sufficient computational resources.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_layers</span></code>: List of layer names to extract embeddings from. Main options:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">[&quot;last_layer&quot;]</span></code>: Uses the final (non-classification) layer of the model. Best for: single-layer probing, baseline experiments, efficient computation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[&quot;all&quot;]</span></code>: Uses all discoverable layers in the model. Best for: multi-layer probing, learning optimal layer combinations, maximum expressiveness.</p></li>
<li><p>Specific layer names: Use concrete layer names (e.g., <code class="docutils literal notranslate"><span class="pre">[&quot;layer_6&quot;,</span> <span class="pre">&quot;layer_12&quot;]</span></code>). Discover available layers using <code class="docutils literal notranslate"><span class="pre">list_model_layers(model_name)</span></code>. Best for: targeted probing of specific layers, custom layer combinations.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">aggregation</span></code>: <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span> <span class="pre">|</span> <span class="pre">&quot;max&quot;</span> <span class="pre">|</span> <span class="pre">&quot;none&quot;</span> <span class="pre">|</span> <span class="pre">&quot;cls_token&quot;</span></code> - Controls how to reduce the time/sequence dimension of embeddings:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: <strong>Average pooling</strong> over the time dimension. Reduces 3D embeddings <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">time,</span> <span class="pre">features)</span></code> to 2D <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">features)</span></code>. Use with <strong>2D probes</strong> (linear, MLP) that expect fixed-size feature vectors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: <strong>Max pooling</strong> over the time dimension. Reduces 3D embeddings <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">time,</span> <span class="pre">features)</span></code> to 2D <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">features)</span></code>. Alternative to mean pooling, can capture peak activations. Use with <strong>2D probes</strong> (linear, MLP).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: <strong>No aggregation</strong> - preserves the full sequence structure <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">time,</span> <span class="pre">features)</span></code>. Required for <strong>3D probes</strong> (LSTM, attention, transformer) that process sequences. Also enables learned weighted combination of multiple layers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;cls_token&quot;</span></code>: Uses only the <strong>first token</strong> (CLS token) from transformer models. Reduces to 2D <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">features)</span></code>. Use with transformer-based backbones and 2D probes.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_processing</span></code>: <code class="docutils literal notranslate"><span class="pre">&quot;pooled&quot;</span> <span class="pre">|</span> <span class="pre">&quot;sequence&quot;</span> <span class="pre">|</span> <span class="pre">&quot;flatten&quot;</span> <span class="pre">|</span> <span class="pre">&quot;none&quot;</span></code> - How to process input embeddings before feeding to the probe:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;pooled&quot;</span></code>: <strong>Default</strong> - Pools embeddings to a fixed dimension. Works with embeddings that have already been aggregated (e.g., via <code class="docutils literal notranslate"><span class="pre">aggregation=&quot;mean&quot;</span></code>). Use with <strong>2D probes</strong> (linear, MLP) that expect fixed-size feature vectors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;sequence&quot;</span></code>: <strong>Keeps sequence structure</strong> - Preserves the temporal/sequence dimension <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">time,</span> <span class="pre">features)</span></code>. <strong>Required for 3D probes</strong> (LSTM, attention, transformer) that process sequences. Only compatible with sequence-based probe types. Must use with <code class="docutils literal notranslate"><span class="pre">aggregation=&quot;none&quot;</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;flatten&quot;</span></code>: <strong>Flattens all dimensions</strong> - Reshapes multi-dimensional embeddings into a single vector. Converts any shape to <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">features)</span></code>. Use when you need to flatten complex embeddings (e.g., 4D tensors) for 2D probes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: <strong>No processing</strong> - Uses embeddings as-is without any transformation. Use when embeddings are already in the correct format for your probe type.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Training behavior</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">freeze_backbone</span></code>: <code class="docutils literal notranslate"><span class="pre">True</span></code> to keep base model frozen</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">online_training</span></code>: <code class="docutils literal notranslate"><span class="pre">True</span></code> for online (end-to-end graph) vs <code class="docutils literal notranslate"><span class="pre">False</span></code> for pure offline</p></li>
</ul>
</li>
<li><p><strong>Probe-specific parameters</strong></p>
<ul class="simple">
<li><p><strong>MLP</strong>: <code class="docutils literal notranslate"><span class="pre">hidden_dims</span></code>, <code class="docutils literal notranslate"><span class="pre">dropout_rate</span></code>, <code class="docutils literal notranslate"><span class="pre">activation</span></code>, …</p></li>
<li><p><strong>LSTM</strong>: <code class="docutils literal notranslate"><span class="pre">lstm_hidden_size</span></code>, <code class="docutils literal notranslate"><span class="pre">num_layers</span></code>, <code class="docutils literal notranslate"><span class="pre">bidirectional</span></code>, <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code>, …</p></li>
<li><p><strong>Attention/Transformer</strong>: <code class="docutils literal notranslate"><span class="pre">num_heads</span></code>, <code class="docutils literal notranslate"><span class="pre">attention_dim</span></code>, <code class="docutils literal notranslate"><span class="pre">num_layers</span></code>, <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code>, <code class="docutils literal notranslate"><span class="pre">use_positional_encoding</span></code>, …</p></li>
</ul>
<p>See <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code> class documentation or use <code class="docutils literal notranslate"><span class="pre">ProbeConfig.model_json_schema()</span></code> for complete parameter details, defaults, and valid ranges.</p>
</li>
</ul>
</section>
<section id="example-minimal-linear-probe-python">
<h3>Example: Minimal Linear Probe (Python)<a class="headerlink" href="#example-minimal-linear-probe-python" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbeConfig</span>

<span class="n">probe_config</span> <span class="o">=</span> <span class="n">ProbeConfig</span><span class="p">(</span>
    <span class="n">probe_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="n">target_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;backbone&quot;</span><span class="p">],</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">freeze_backbone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">online_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example-yaml-probe-definition">
<h3>Example: YAML Probe Definition<a class="headerlink" href="#example-yaml-probe-definition" title="Link to this heading">¶</a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># my_linear_probe.yml</span>
<span class="nt">probe_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">linear</span>
<span class="nt">target_layers</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&quot;backbone&quot;</span><span class="p p-Indicator">]</span>
<span class="nt">aggregation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mean</span>
<span class="nt">freeze_backbone</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">online_training</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">load_probe_config</span><span class="p">,</span>
    <span class="n">build_probe_from_config</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_model</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">load_probe_config</span><span class="p">(</span><span class="s2">&quot;my_linear_probe.yml&quot;</span><span class="p">)</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;esp_aves2_naturelm_audio_v1_beats&quot;</span><span class="p">,</span> <span class="n">return_features_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">probe</span> <span class="o">=</span> <span class="n">build_probe_from_config</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">base_model</span><span class="o">=</span><span class="n">base</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="api-reference">
<h2>API Reference<a class="headerlink" href="#api-reference" title="Link to this heading">¶</a></h2>
<section id="factory-functions">
<h3>Factory Functions<a class="headerlink" href="#factory-functions" title="Link to this heading">¶</a></h3>
<section id="build-probe-from-config">
<h4><code class="docutils literal notranslate"><span class="pre">build_probe_from_config()</span></code><a class="headerlink" href="#build-probe-from-config" title="Link to this heading">¶</a></h4>
<p>Unified factory function for building probe instances from a <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code>. Supports both <strong>online</strong> (with base model) and <strong>offline</strong> (with pre-computed embeddings) modes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_probe_from_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbeConfig</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_probe_from_config</span><span class="p">(</span>
    <span class="n">probe_config</span><span class="p">:</span> <span class="n">ProbeConfig</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">base_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">target_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="o">...</span>
</pre></div>
</div>
<p><strong>Key parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">probe_config</span></code>: The <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code> object.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_classes</span></code>: Number of output classes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device</span></code>: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;cuda&quot;</span></code>, etc.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">base_model</span></code>: Optional backbone model to attach the probe to (for online mode).
If provided, probe will be attached for end-to-end training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_dim</span></code>: Optional embedding dimension (for offline mode).
Required if <code class="docutils literal notranslate"><span class="pre">base_model</span></code> is None.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_length</span></code>: Optional audio target length override.</p></li>
</ul>
<p><strong>Mode detection:</strong></p>
<ul class="simple">
<li><p><strong>Online mode</strong>: When <code class="docutils literal notranslate"><span class="pre">base_model</span></code> is provided, the probe is attached to the base model for end-to-end training.</p></li>
<li><p><strong>Offline mode</strong>: When <code class="docutils literal notranslate"><span class="pre">input_dim</span></code> is provided, the probe operates on pre-computed embeddings without a base model.</p></li>
</ul>
<p><strong>Returns:</strong> A <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> probe ready for training/inference.</p>
</section>
</section>
<section id="config-helpers">
<h3>Config Helpers<a class="headerlink" href="#config-helpers" title="Link to this heading">¶</a></h3>
<section id="load-probe-config">
<h4><code class="docutils literal notranslate"><span class="pre">load_probe_config()</span></code><a class="headerlink" href="#load-probe-config" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_probe_config</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">load_probe_config</span><span class="p">(</span><span class="s2">&quot;my_probe.yml&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Supports:</p>
<ul class="simple">
<li><p>Files with top-level probe fields.</p></li>
<li><p>Files with a nested <code class="docutils literal notranslate"><span class="pre">probe_config:</span> <span class="pre">{...}</span></code> block.</p></li>
</ul>
</section>
</section>
<section id="configuration-structure">
<h3>Configuration Structure<a class="headerlink" href="#configuration-structure" title="Link to this heading">¶</a></h3>
<p>All probe configs include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">probe_type</span></code> - Type of probe architecture</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_layers</span></code> - Which layers to extract features from</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">aggregation</span></code> - How to aggregate features (mean, max, none)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_processing</span></code> - How to process inputs (pooled, sequence, flatten)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">freeze_backbone</span></code> - Whether to freeze backbone weights</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">online_training</span></code> - Whether to train end-to-end or offline</p></li>
</ul>
<p><strong>Probe-specific parameters:</strong></p>
<ul class="simple">
<li><p><strong>MLP</strong>: <code class="docutils literal notranslate"><span class="pre">hidden_dims</span></code>, <code class="docutils literal notranslate"><span class="pre">dropout_rate</span></code>, <code class="docutils literal notranslate"><span class="pre">activation</span></code></p></li>
<li><p><strong>LSTM</strong>: <code class="docutils literal notranslate"><span class="pre">lstm_hidden_size</span></code>, <code class="docutils literal notranslate"><span class="pre">num_layers</span></code>, <code class="docutils literal notranslate"><span class="pre">bidirectional</span></code>, <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code></p></li>
<li><p><strong>Attention</strong>: <code class="docutils literal notranslate"><span class="pre">num_heads</span></code>, <code class="docutils literal notranslate"><span class="pre">attention_dim</span></code>, <code class="docutils literal notranslate"><span class="pre">num_layers</span></code>, <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code></p></li>
<li><p><strong>Transformer</strong>: <code class="docutils literal notranslate"><span class="pre">num_heads</span></code>, <code class="docutils literal notranslate"><span class="pre">attention_dim</span></code>, <code class="docutils literal notranslate"><span class="pre">num_layers</span></code>, <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code></p></li>
</ul>
</section>
</section>
<section id="usage-examples">
<h2>Usage Examples<a class="headerlink" href="#usage-examples" title="Link to this heading">¶</a></h2>
<section id="comparing-different-probe-architectures">
<h3>Comparing Different Probe Architectures<a class="headerlink" href="#comparing-different-probe-architectures" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_probe_from_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbeConfig</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;esp_aves2_naturelm_audio_v1_beats&quot;</span><span class="p">,</span> <span class="n">return_features_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="n">probe_types</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;aggregation&quot;</span><span class="p">:</span> <span class="s2">&quot;mean&quot;</span><span class="p">}),</span>
    <span class="p">(</span><span class="s2">&quot;mlp&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;aggregation&quot;</span><span class="p">:</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;hidden_dims&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">]}),</span>
    <span class="p">(</span><span class="s2">&quot;attention&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;input_processing&quot;</span><span class="p">:</span> <span class="s2">&quot;sequence&quot;</span><span class="p">,</span> <span class="s2">&quot;num_heads&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;attention_dim&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">}),</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">probe_type</span><span class="p">,</span> <span class="n">extra_cfg</span> <span class="ow">in</span> <span class="n">probe_types</span><span class="p">:</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">ProbeConfig</span><span class="p">(</span>
        <span class="n">probe_type</span><span class="o">=</span><span class="n">probe_type</span><span class="p">,</span>
        <span class="n">target_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;backbone&quot;</span><span class="p">],</span>
        <span class="n">freeze_backbone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">online_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">extra_cfg</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">probe</span> <span class="o">=</span> <span class="n">build_probe_from_config</span><span class="p">(</span>
        <span class="n">probe_config</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span>
        <span class="n">base_model</span><span class="o">=</span><span class="n">base</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">probe_type</span><span class="p">,</span> <span class="s2">&quot;parameters:&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probe</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
</pre></div>
</div>
<p>Expected output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linear</span> <span class="n">parameters</span><span class="p">:</span> <span class="mi">7680</span>
<span class="n">mlp</span> <span class="n">parameters</span><span class="p">:</span> <span class="mi">395264</span>
<span class="n">attention</span> <span class="n">parameters</span><span class="p">:</span> <span class="mi">66560</span>
</pre></div>
</div>
</section>
<section id="load-from-custom-yaml">
<h3>Load from Custom YAML<a class="headerlink" href="#load-from-custom-yaml" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># custom_probe.yml</span>
<span class="c1"># probe_type: mlp</span>
<span class="c1"># target_layers: [&quot;backbone&quot;]</span>
<span class="c1"># aggregation: mean</span>
<span class="c1"># hidden_dims: [1024, 512]</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">build_probe_from_config</span><span class="p">,</span>
    <span class="n">load_probe_config</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_model</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">load_probe_config</span><span class="p">(</span><span class="s2">&quot;custom_probe.yml&quot;</span><span class="p">)</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;esp_aves2_naturelm_audio_v1_beats&quot;</span><span class="p">,</span> <span class="n">return_features_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">probe</span> <span class="o">=</span> <span class="n">build_probe_from_config</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">base_model</span><span class="o">=</span><span class="n">base</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-probeconfig-programmatically">
<h3>Using ProbeConfig Programmatically<a class="headerlink" href="#using-probeconfig-programmatically" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbeConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_probe_from_config</span>

<span class="c1"># Create config programmatically</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">ProbeConfig</span><span class="p">(</span>
    <span class="n">probe_type</span><span class="o">=</span><span class="s2">&quot;attention&quot;</span><span class="p">,</span>
    <span class="n">target_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;layer_12&quot;</span><span class="p">],</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">input_processing</span><span class="o">=</span><span class="s2">&quot;sequence&quot;</span><span class="p">,</span>
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">attention_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Use it</span>
<span class="n">probe</span> <span class="o">=</span> <span class="n">build_probe_from_config</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">base_model</span><span class="o">=</span><span class="n">my_model</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="implementation-details">
<h2>Implementation Details<a class="headerlink" href="#implementation-details" title="Link to this heading">¶</a></h2>
<section id="architecture">
<h3>Architecture<a class="headerlink" href="#architecture" title="Link to this heading">¶</a></h3>
<p>The probe API mirrors the model API structure for consistency:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>avex/
├── models/probes/
│   ├── utils/                          # Probe utilities (parallel to models/utils/)
│   │   ├── __init__.py
│   │   ├── registry.py                 # Probe class discovery + YAML helpers
│   │   └── factory.py                  # build_probe_from_config
│   └── [probe implementations]
└── examples/
    └── 07_probe_training_and_inference.py  # Usage examples
</pre></div>
</div>
</section>
<section id="core-components">
<h3>Core Components<a class="headerlink" href="#core-components" title="Link to this heading">¶</a></h3>
<section id="registry-py">
<h4><code class="docutils literal notranslate"><span class="pre">registry.py</span></code><a class="headerlink" href="#registry-py" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Probe Class Registry</strong>: <code class="docutils literal notranslate"><span class="pre">_PROBE_CLASSES</span></code> for discovered probe implementations</p></li>
<li><p><strong>Discovery</strong>: Dynamically finds all probe classes (LinearProbe, MLPProbe, etc.)</p></li>
<li><p><strong>YAML Helpers</strong>: <code class="docutils literal notranslate"><span class="pre">load_probe_config()</span></code> for loading <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code> from disk</p></li>
</ul>
</section>
<section id="factory-py">
<h4><code class="docutils literal notranslate"><span class="pre">factory.py</span></code><a class="headerlink" href="#factory-py" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>build_probe_from_config()</strong>: Unified factory for building probes from <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code> (supports both online and offline modes)</p></li>
<li><p>Handle parameter filtering and base-model interaction (freezing, hooks, feature-mode)</p></li>
</ul>
</section>
</section>
</section>
<section id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="Link to this heading">¶</a></h2>
<section id="verify-installation">
<h3>Verify Installation<a class="headerlink" href="#verify-installation" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">avex.models.probes</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_probe_from_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">avex.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbeConfig</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Test offline mode (works independently)</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">ProbeConfig</span><span class="p">(</span>
    <span class="n">probe_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="n">target_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;backbone&quot;</span><span class="p">],</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">freeze_backbone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">online_training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">probe</span> <span class="o">=</span> <span class="n">build_probe_from_config</span><span class="p">(</span>
    <span class="n">cfg</span><span class="p">,</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Test forward pass (inference mode)</span>
<span class="n">probe</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">dummy_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">probe</span><span class="p">(</span><span class="n">dummy_embeddings</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output shape: </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Should be (2, 10)</span>
</pre></div>
</div>
</section>
<section id="run-example-script">
<h3>Run Example Script<a class="headerlink" href="#run-example-script" title="Link to this heading">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/home/marius/code/avex
python<span class="w"> </span>examples/07_probe_training_and_inference.py
</pre></div>
</div>
</section>
</section>
<section id="tested-functionality">
<h2>Tested Functionality<a class="headerlink" href="#tested-functionality" title="Link to this heading">¶</a></h2>
<p>✅ <strong>Probe Discovery</strong>: Automatically finds all probe classes</p>
<p>✅ <strong>Config Loading</strong>: <code class="docutils literal notranslate"><span class="pre">load_probe_config()</span></code> builds <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code> from YAML</p>
<p>✅ <strong>Factory Usage</strong>: <code class="docutils literal notranslate"><span class="pre">build_probe_from_config()</span></code> builds probes from <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code> (supports both online and offline modes)</p>
<p>✅ <strong>Offline Mode</strong>: Creates probes for pre-computed embeddings</p>
<p>✅ <strong>Online Mode</strong>: Loads and attaches to base models</p>
<p>✅ <strong>Forward Pass</strong>: Correct output shapes with dummy data</p>
<p>✅ <strong>No Linter Errors</strong>: All code is ruff-compliant</p>
<p>✅ <strong>Layer Variants</strong>: <code class="docutils literal notranslate"><span class="pre">_last</span></code> and <code class="docutils literal notranslate"><span class="pre">_all</span></code> variants work correctly</p>
</section>
<section id="known-issues">
<h2>Known Issues<a class="headerlink" href="#known-issues" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><strong>Model Registry</strong>: Pre-existing circular import prevents model loading in some contexts</p>
<ul>
<li><p>This is a separate issue in the existing codebase</p></li>
<li><p>Doesn’t affect offline probe functionality</p></li>
<li><p>Doesn’t affect direct model instance usage</p></li>
</ul>
</li>
</ul>
</section>
<section id="files-created">
<h2>Files Created<a class="headerlink" href="#files-created" title="Link to this heading">¶</a></h2>
<section id="core-implementation">
<h3>Core Implementation<a class="headerlink" href="#core-implementation" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">models/probes/utils/__init__.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">models/probes/utils/registry.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">models/probes/utils/factory.py</span></code></p></li>
</ul>
</section>
<section id="examples-and-documentation">
<h3>Examples and Documentation<a class="headerlink" href="#examples-and-documentation" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/earthspecies/avex/blob/main/examples/07_probe_training_and_inference.py" rel="noreferer noopener" target="_blank"><code class="docutils literal notranslate"><span class="pre">examples/07_probe_training_and_inference.py</span></code></a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">docs/api_probes.md</span></code> (this file)</p></li>
</ul>
</section>
</section>
<section id="future-enhancements">
<h2>Future Enhancements<a class="headerlink" href="#future-enhancements" title="Link to this heading">¶</a></h2>
<p>The following components were intentionally not implemented:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">models/probes/utils/checkpoint.py</span></code> - Checkpoint save/load utilities</p></li>
<li><p>Embedding extraction utilities</p></li>
</ul>
<p>These can be added in future iterations following the same design patterns.</p>
</section>
<section id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/earthspecies/avex/blob/main/examples/07_probe_training_and_inference.py" rel="noreferer noopener" target="_blank"><code class="docutils literal notranslate"><span class="pre">examples/07_probe_training_and_inference.py</span></code></a> - Complete usage examples</p></li>
<li><p><a class="reference external" href="https://github.com/earthspecies/avex/tree/main/avex/models/probes" rel="noreferer noopener" target="_blank"><code class="docutils literal notranslate"><span class="pre">avex/models/probes/</span></code></a> - Probe implementations</p></li>
<li><p>Model API documentation for parallel structure reference</p></li>
</ul>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="custom_model_registration.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Custom Model Registration Guide</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="probe_system.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Flexible Probe System</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2026, Earth Species Project
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Probe API Documentation</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#getting-started">Getting Started</a><ul>
<li><a class="reference internal" href="#start-simple">1. Start Simple</a></li>
<li><a class="reference internal" href="#increase-complexity-if-needed">2. Increase Complexity If Needed</a></li>
<li><a class="reference internal" href="#match-probe-complexity-to-task">3. Match Probe Complexity to Task</a></li>
<li><a class="reference internal" href="#consider-computational-budget">4. Consider Computational Budget</a></li>
<li><a class="reference internal" href="#performance-trade-offs">Performance Trade-offs</a><ul>
<li><a class="reference internal" href="#last-variants"><code class="docutils literal notranslate"><span class="pre">_last</span></code> Variants</a></li>
<li><a class="reference internal" href="#all-variants"><code class="docutils literal notranslate"><span class="pre">_all</span></code> Variants</a></li>
</ul>
</li>
<li><a class="reference internal" href="#quick-selection-guide">Quick Selection Guide</a></li>
</ul>
</li>
<li><a class="reference internal" href="#quick-start">Quick Start</a><ul>
<li><a class="reference internal" href="#build-and-use-a-probe-online-mode">Build and Use a Probe (Online Mode)</a></li>
<li><a class="reference internal" href="#offline-mode-pre-computed-embeddings">Offline Mode (Pre-computed Embeddings)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#defining-probe-configurations">Defining Probe Configurations</a><ul>
<li><a class="reference internal" href="#probe-types">Probe Types</a></li>
<li><a class="reference internal" href="#core-fields-in-probeconfig">Core Fields in <code class="docutils literal notranslate"><span class="pre">ProbeConfig</span></code></a></li>
<li><a class="reference internal" href="#example-minimal-linear-probe-python">Example: Minimal Linear Probe (Python)</a></li>
<li><a class="reference internal" href="#example-yaml-probe-definition">Example: YAML Probe Definition</a></li>
</ul>
</li>
<li><a class="reference internal" href="#api-reference">API Reference</a><ul>
<li><a class="reference internal" href="#factory-functions">Factory Functions</a><ul>
<li><a class="reference internal" href="#build-probe-from-config"><code class="docutils literal notranslate"><span class="pre">build_probe_from_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#config-helpers">Config Helpers</a><ul>
<li><a class="reference internal" href="#load-probe-config"><code class="docutils literal notranslate"><span class="pre">load_probe_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#configuration-structure">Configuration Structure</a></li>
</ul>
</li>
<li><a class="reference internal" href="#usage-examples">Usage Examples</a><ul>
<li><a class="reference internal" href="#comparing-different-probe-architectures">Comparing Different Probe Architectures</a></li>
<li><a class="reference internal" href="#load-from-custom-yaml">Load from Custom YAML</a></li>
<li><a class="reference internal" href="#using-probeconfig-programmatically">Using ProbeConfig Programmatically</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-details">Implementation Details</a><ul>
<li><a class="reference internal" href="#architecture">Architecture</a></li>
<li><a class="reference internal" href="#core-components">Core Components</a><ul>
<li><a class="reference internal" href="#registry-py"><code class="docutils literal notranslate"><span class="pre">registry.py</span></code></a></li>
<li><a class="reference internal" href="#factory-py"><code class="docutils literal notranslate"><span class="pre">factory.py</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#testing">Testing</a><ul>
<li><a class="reference internal" href="#verify-installation">Verify Installation</a></li>
<li><a class="reference internal" href="#run-example-script">Run Example Script</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tested-functionality">Tested Functionality</a></li>
<li><a class="reference internal" href="#known-issues">Known Issues</a></li>
<li><a class="reference internal" href="#files-created">Files Created</a><ul>
<li><a class="reference internal" href="#core-implementation">Core Implementation</a></li>
<li><a class="reference internal" href="#examples-and-documentation">Examples and Documentation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#future-enhancements">Future Enhancements</a></li>
<li><a class="reference internal" href="#see-also">See Also</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=8d563738"></script>
    <script src="_static/doctools.js?v=fd6eb6e6"></script>
    <script src="_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    </body>
</html>